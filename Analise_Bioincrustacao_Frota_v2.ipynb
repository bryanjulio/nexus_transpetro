{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo de predi√ß√£o Nexus**"
      ],
      "metadata": {
        "id": "GPNcvUPLCIP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas numpy matplotlib seaborn tqdm scikit-learn xgboost lightgbm gdown openpyxl rich\n",
        "print('‚úÖ Todas as bibliotecas foram instaladas com sucesso!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3uEBuSSBWIt",
        "outputId": "18bfec82-15f0-474a-e02d-4d7ffbf83707"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Todas as bibliotecas foram instaladas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Analise_Bioincrustacao_Frota_v2.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/bryanjulio/nexus_transpetro/blob/main/Analise_Bioincrustacao_Frota_v2.ipynb\n",
        "\n",
        "# Predi√ß√£o de Bioincrusta√ß√£o Nexus\n",
        "\"\"\"\n",
        "\n",
        "import pkg_resources\n",
        "import sys\n",
        "\n",
        "def create_requirements_file(filename=\"requirements.txt\"):\n",
        "    # List of libraries explicitly used in the notebook\n",
        "    explicit_dependencies = [\n",
        "        'pandas',\n",
        "        'numpy',\n",
        "        'matplotlib',\n",
        "        'seaborn',\n",
        "        'tqdm',\n",
        "        'scikit-learn',\n",
        "        'xgboost',\n",
        "        'lightgbm',\n",
        "        'gdown', # Included if used for data download\n",
        "        'openpyxl' # For reading/writing excel files, if applicable\n",
        "    ]\n",
        "\n",
        "    # Get all installed packages\n",
        "    installed_packages = {p.project_name.lower(): p for p in pkg_resources.working_set}\n",
        "\n",
        "    reqs = []\n",
        "    for dep_name in explicit_dependencies:\n",
        "        try:\n",
        "            # Try to get the package, handling case-insensitivity\n",
        "            package = installed_packages.get(dep_name.lower())\n",
        "            if package:\n",
        "                reqs.append(f\"{package.project_name}=={package.version}\")\n",
        "            else:\n",
        "                print(f\"Warning: '{dep_name}' specified but not found in environment. Skipping.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing '{dep_name}': {e}. Skipping.\")\n",
        "\n",
        "    with open(filename, \"w\") as f:\n",
        "        for r in sorted(reqs):\n",
        "            f.write(r + \"\\n\")\n",
        "    print(f\"Generated '{filename}' with {len(reqs)} key dependencies.\")\n",
        "    print(\"Please review the file and add any missing dependencies or remove unnecessary ones.\")\n",
        "\n",
        "create_requirements_file()\n",
        "\n",
        "# import subprocess\n",
        "# subprocess.run([\"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
        "\n",
        "\"\"\"\n",
        "Predi√ß√£o de Bioincrusta√ß√£o - An√°lise Avan√ßada de Fouling\n",
        "\n",
        "\n",
        "1. Features de tempo ocioso (idle time)\n",
        "2. Features de velocidade de risco\n",
        "3. Progress√£o temporal da bioincrusta√ß√£o\n",
        "4. Valida√ß√£o temporal (n√£o aleat√≥ria)\n",
        "5. Modelo ensemble (XGBoost, LightGBM, RF, GB)\n",
        "6. Target baseado em Fouling Rating IMO (0-4)\n",
        "7. An√°lise de cen√°rios futuros\n",
        "8. Impacto econ√¥mico realista (5-25% penalty)\n",
        "9. An√°lise individual por navio da frota\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import zipfile\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML imports\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import pickle\n",
        "\n",
        "# Rich imports para visualiza√ß√£o\n",
        "try:\n",
        "    from rich.console import Console\n",
        "    from rich.table import Table\n",
        "    from rich.panel import Panel\n",
        "    from rich.text import Text\n",
        "    from rich import box\n",
        "    RICH_AVAILABLE = True\n",
        "    console = Console()\n",
        "except ImportError:\n",
        "    RICH_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è Rich n√£o dispon√≠vel. Usando visualiza√ß√£o padr√£o.\")\n",
        "    print(\"   Instale com: pip install rich\")\n",
        "\n",
        "# Configura√ß√µes\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "if RICH_AVAILABLE:\n",
        "    console.print(\"[green]‚úì[/green] Bibliotecas importadas com sucesso!\", style=\"bold\")\n",
        "else:\n",
        "    print(\"‚úì Bibliotecas importadas com sucesso!\")\n",
        "\n",
        "# Fun√ß√µes auxiliares para impress√£o limpa\n",
        "def print_header(title):\n",
        "    \"\"\"Imprime cabe√ßalho de se√ß√£o\"\"\"\n",
        "    if RICH_AVAILABLE:\n",
        "        console.print(f\"\\n[bold cyan]{title}[/bold cyan]\")\n",
        "        console.print(\"‚îÄ\" * len(title), style=\"cyan\")\n",
        "    else:\n",
        "        print(f\"\\n{title}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "def print_info(message):\n",
        "    \"\"\"Imprime mensagem informativa\"\"\"\n",
        "    if RICH_AVAILABLE:\n",
        "        console.print(f\"  {message}\")\n",
        "    else:\n",
        "        print(f\"  {message}\")\n",
        "\n",
        "def print_success(message):\n",
        "    \"\"\"Imprime mensagem de sucesso\"\"\"\n",
        "    if RICH_AVAILABLE:\n",
        "        console.print(f\"[green]‚úì[/green] {message}\")\n",
        "    else:\n",
        "        print(f\"‚úì {message}\")\n",
        "\n",
        "def print_warning(message):\n",
        "    \"\"\"Imprime aviso\"\"\"\n",
        "    if RICH_AVAILABLE:\n",
        "        console.print(f\"[yellow]‚ö†[/yellow] {message}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è {message}\")\n",
        "\n",
        "def create_results_table(df_results, title=\"Resultados\"):\n",
        "    \"\"\"Cria tabela formatada de resultados\"\"\"\n",
        "    if not RICH_AVAILABLE:\n",
        "        return df_results.to_string(index=False)\n",
        "\n",
        "    table = Table(title=title, box=box.SIMPLE, show_header=True, header_style=\"bold\")\n",
        "\n",
        "    # Adicionar colunas\n",
        "    for col in df_results.columns:\n",
        "        table.add_column(col, justify=\"right\" if df_results[col].dtype in ['int64', 'float64'] else \"left\")\n",
        "\n",
        "    # Adicionar linhas\n",
        "    for _, row in df_results.iterrows():\n",
        "        table.add_row(*[str(val) for val in row])\n",
        "\n",
        "    return table\n",
        "\n",
        "import pkg_resources\n",
        "import sys\n",
        "\n",
        "def create_requirements_file(filename=\"requirements.txt\"):\n",
        "    # List of libraries explicitly used in the notebook\n",
        "    explicit_dependencies = [\n",
        "        'pandas',\n",
        "        'numpy',\n",
        "        'matplotlib',\n",
        "        'seaborn',\n",
        "        'tqdm',\n",
        "        'scikit-learn',\n",
        "        'xgboost',\n",
        "        'lightgbm',\n",
        "        'gdown', # Included if used for data download\n",
        "        'openpyxl' # For reading/writing excel files, if applicable\n",
        "    ]\n",
        "\n",
        "    # Get all installed packages\n",
        "    installed_packages = {p.project_name.lower(): p for p in pkg_resources.working_set}\n",
        "\n",
        "    reqs = []\n",
        "    for dep_name in explicit_dependencies:\n",
        "        try:\n",
        "            # Try to get the package, handling case-insensitivity\n",
        "            package = installed_packages.get(dep_name.lower())\n",
        "            if package:\n",
        "                reqs.append(f\"{package.project_name}=={package.version}\")\n",
        "            else:\n",
        "                print(f\"Warning: '{dep_name}' specified but not found in environment. Skipping.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing '{dep_name}': {e}. Skipping.\")\n",
        "\n",
        "    # Additionally, check for packages in the current environment that might be implied\n",
        "    # This part is more general and might pick up extras, but ensures coverage\n",
        "    # For a more precise list, manually curate explicit_dependencies.\n",
        "\n",
        "    # Get all direct imports in the current kernel, though this is harder to automate perfectly.\n",
        "    # For simplicity, we stick to explicit_dependencies here unless a more complex introspection is needed.\n",
        "\n",
        "    with open(filename, \"w\") as f:\n",
        "        for r in sorted(reqs):\n",
        "            f.write(r + \"\\n\")\n",
        "    print(f\"Generated '{filename}' with {len(reqs)} key dependencies.\")\n",
        "    print(\"Please review the file and add any missing dependencies or remove unnecessary ones.\")\n",
        "\n",
        "create_requirements_file()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "0j-uFOsvFh-O",
        "outputId": "e1205847-6e34-43ed-bbb4-234c7e3fbc15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 'requirements.txt' with 10 key dependencies.\n",
            "Please review the file and add any missing dependencies or remove unnecessary ones.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32m‚úì\u001b[0m\u001b[1m Bibliotecas importadas com sucesso!\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">‚úì</span><span style=\"font-weight: bold\"> Bibliotecas importadas com sucesso!</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 'requirements.txt' with 10 key dependencies.\n",
            "Please review the file and add any missing dependencies or remove unnecessary ones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. DOWNLOAD DOS DADOS DO GOOGLE DRIVE (OPCIONAL)"
      ],
      "metadata": {
        "id": "8oS6LHUeCBYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se os dados n√£o existirem localmente, baixar do Google Drive\n",
        "DOWNLOAD_FROM_DRIVE = True  # Altere para True para baixar do Drive\n",
        "\n",
        "if DOWNLOAD_FROM_DRIVE:\n",
        "    try:\n",
        "        import gdown\n",
        "        print(\"\\n Baixando dados do Google Drive...\")\n",
        "\n",
        "        folder_url = \"https://drive.google.com/drive/folders/1NJrDlremklekCO1NR4Ltm43DZBOCKdW6\"\n",
        "        gdown.download_folder(folder_url, quiet=False, use_cookies=False, output=\"Hackathon Transpetro\")\n",
        "\n",
        "        print(\" Dados baixados com sucesso!\")\n",
        "        BASE_PATH = \"Dados Hackathon Transpetro/\"\n",
        "    except ImportError:\n",
        "        print(\" gdown n√£o instalado. Execute: pip install gdown\")\n",
        "        print(\"   Usando dados locais...\")\n",
        "        BASE_PATH = \"\"\n",
        "    except Exception as e:\n",
        "        print(f\" Erro ao baixar do Drive: {e}\")\n",
        "        print(\"   Usando dados locais...\")\n",
        "        BASE_PATH = \"\"\n",
        "else:\n",
        "    BASE_PATH = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2GzE48tB3i5",
        "outputId": "f45a1949-868e-46a9-f152-adf89954185c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Baixando dados do Google Drive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder 1oSLdQSsW0GpFgGoRZF12zFxFNs72P0sH Mais Dados\n",
            "Processing file 1IzjTamdx1iq2MTi2VkrO6lAYF3s_uSIL AIS_NAVIO TESTE 2 1.csv\n",
            "Processing file 1rP-GH7HLBMLS-DAQ6st9689wDtgY3YMe AIS_NAVIO TESTE 3 1.csv\n",
            "Processing file 17PjAApZZCyk_2epri9x-CRyD-1BoUPor Consumo_Validacao 1.CSV\n",
            "Processing file 1MoajA9gX0OHrEFdGyBRDh5DSXg0H7X-S Dados navios Valida√ß√£o 1.xlsx\n",
            "Processing file 1xksJEcxznpN_anRavD_0x-4c2t8hQYRN Eventos_Validacao 1.CSV\n",
            "Processing file 1BNU0xrGH54VYviSBNKGZG5Xkya4CTf0C RESULTADO Valida√ß√£o 1.xlsx\n",
            "Processing file 17-kgs1RS52wenFcfpHr2ljbkq-4TG2Cf Dados AIS frota TP.zip\n",
            "Processing file 1_CTM1V1PFN2guPl2ipW-VjdM80i8i7Ll Dados navios Hackathon.xlsx\n",
            "Processing file 1L-iN3artAlSB3hqC6pQsX58z_9HKbmVw Dicion√°rios de Dados.xlsx\n",
            "Processing file 1YYp8B3finjq-p53MURKGyPXUQt26ZIuf Manual do Participante.pdf\n",
            "Processing file 1ikd9AFsF18LZTAW8mRofQhVWaXzN98ek Relatorios IWS.xlsx\n",
            "Processing file 1XUPl_mDEVjtlM6g19Q-oyaRWB9Gn6a0M ResultadoQueryConsumo.csv\n",
            "Processing file 1S4iA70w2SapFOrNz1UAAWuWL1xBOD-7D ResultadoQueryEventos.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IzjTamdx1iq2MTi2VkrO6lAYF3s_uSIL\n",
            "To: /content/Hackathon Transpetro/Mais Dados/AIS_NAVIO TESTE 2 1.csv\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 988k/988k [00:00<00:00, 3.46MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rP-GH7HLBMLS-DAQ6st9689wDtgY3YMe\n",
            "To: /content/Hackathon Transpetro/Mais Dados/AIS_NAVIO TESTE 3 1.csv\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.22M/1.22M [00:00<00:00, 108MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17PjAApZZCyk_2epri9x-CRyD-1BoUPor\n",
            "To: /content/Hackathon Transpetro/Mais Dados/Consumo_Validacao 1.CSV\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 191k/191k [00:00<00:00, 81.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MoajA9gX0OHrEFdGyBRDh5DSXg0H7X-S\n",
            "To: /content/Hackathon Transpetro/Mais Dados/Dados navios Valida√ß√£o 1.xlsx\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.9k/12.9k [00:00<00:00, 7.50MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xksJEcxznpN_anRavD_0x-4c2t8hQYRN\n",
            "To: /content/Hackathon Transpetro/Mais Dados/Eventos_Validacao 1.CSV\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 586k/586k [00:00<00:00, 75.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BNU0xrGH54VYviSBNKGZG5Xkya4CTf0C\n",
            "To: /content/Hackathon Transpetro/Mais Dados/RESULTADO Valida√ß√£o 1.xlsx\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.5k/10.5k [00:00<00:00, 24.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17-kgs1RS52wenFcfpHr2ljbkq-4TG2Cf\n",
            "To: /content/Hackathon Transpetro/Dados AIS frota TP.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.47M/6.47M [00:00<00:00, 62.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_CTM1V1PFN2guPl2ipW-VjdM80i8i7Ll\n",
            "To: /content/Hackathon Transpetro/Dados navios Hackathon.xlsx\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.4k/16.4k [00:00<00:00, 39.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L-iN3artAlSB3hqC6pQsX58z_9HKbmVw\n",
            "To: /content/Hackathon Transpetro/Dicion√°rios de Dados.xlsx\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19.0k/19.0k [00:00<00:00, 17.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YYp8B3finjq-p53MURKGyPXUQt26ZIuf\n",
            "To: /content/Hackathon Transpetro/Manual do Participante.pdf\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.90M/3.90M [00:00<00:00, 243MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ikd9AFsF18LZTAW8mRofQhVWaXzN98ek\n",
            "To: /content/Hackathon Transpetro/Relatorios IWS.xlsx\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.8k/15.8k [00:00<00:00, 26.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XUPl_mDEVjtlM6g19Q-oyaRWB9Gn6a0M\n",
            "To: /content/Hackathon Transpetro/ResultadoQueryConsumo.csv\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.39M/2.39M [00:00<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S4iA70w2SapFOrNz1UAAWuWL1xBOD-7D\n",
            "To: /content/Hackathon Transpetro/ResultadoQueryEventos.csv\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.35M/8.35M [00:00<00:00, 189MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dados baixados com sucesso!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. CARREGAMENTO DOS DADOS"
      ],
      "metadata": {
        "id": "j3dSrfsQB-aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se n√£o foi definido BASE_PATH no download, usar caminho local\n",
        "if 'BASE_PATH' not in locals():\n",
        "    BASE_PATH = \"/Users/bryan/Documents/Hackathon_transpetro/\"\n",
        "\n",
        "# Tentar m√∫ltiplos caminhos poss√≠veis\n",
        "data_paths = [\n",
        "    BASE_PATH,\n",
        "    \"Hackathon Transpetro/\",\n",
        "    \"/content/Hackathon Transpetro/\",  # Google Colab\n",
        "    \"\"  # Diret√≥rio atual\n",
        "]\n",
        "\n",
        "# Encontrar caminho v√°lido\n",
        "valid_path = None\n",
        "for path in data_paths:\n",
        "    if os.path.exists(f\"{path}ResultadoQueryEventos.csv\"):\n",
        "        valid_path = path\n",
        "        break\n",
        "\n",
        "if valid_path is None:\n",
        "    print(\"‚ö†Ô∏è Dados n√£o encontrados. Configure DOWNLOAD_FROM_DRIVE=True ou ajuste BASE_PATH\")\n",
        "    exit(1)\n",
        "\n",
        "BASE_PATH = valid_path\n",
        "print(f\"\\nüìÇ Carregando dados de: {BASE_PATH}\")\n",
        "\n",
        "df_eventos = pd.read_csv(f\"{BASE_PATH}ResultadoQueryEventos.csv\")\n",
        "df_consumo = pd.read_csv(f\"{BASE_PATH}ResultadoQueryConsumo.csv\")\n",
        "df_navios = pd.read_excel(f\"{BASE_PATH}Dados navios Hackathon.xlsx\")\n",
        "df_iws = pd.read_excel(f\"{BASE_PATH}Relatorios IWS.xlsx\")\n",
        "\n",
        "print(f\" Eventos: {df_eventos.shape}\")\n",
        "print(f\" Consumo: {df_consumo.shape}\")\n",
        "print(f\" Navios: {df_navios.shape}\")\n",
        "print(f\" IWS: {df_iws.shape}\")\n",
        "\n",
        "# Carregar AIS\n",
        "# Tentar m√∫ltiplos caminhos poss√≠veis\n",
        "ais_paths = [\n",
        "    f\"{BASE_PATH}Dados AIS frota TP\",  # Pasta descompactada\n",
        "    f\"{BASE_PATH}notebooks/Dados Hackathon Transpetro/Dados AIS frota TP.zip\",  # ZIP no notebooks\n",
        "    f\"{BASE_PATH}Dados AIS frota TP.zip\"  # ZIP na raiz\n",
        "]\n",
        "\n",
        "df_ais = pd.DataFrame()\n",
        "ais_loaded = False\n",
        "\n",
        "for ais_path in ais_paths:\n",
        "    if os.path.exists(ais_path):\n",
        "        if ais_path.endswith('.zip'):\n",
        "            # √â um ZIP, extrair\n",
        "            extract_folder = \"dados_ais_temp\"\n",
        "            with zipfile.ZipFile(ais_path, \"r\") as z:\n",
        "                z.extractall(extract_folder)\n",
        "            csv_folder = os.path.join(extract_folder, \"Dados AIS frota TP\")\n",
        "        else:\n",
        "            # J√° √© uma pasta\n",
        "            csv_folder = ais_path\n",
        "\n",
        "        # Ler CSVs\n",
        "        all_dfs = []\n",
        "        for file_name in os.listdir(csv_folder):\n",
        "            if file_name.lower().endswith(\".csv\"):\n",
        "                file_path = os.path.join(csv_folder, file_name)\n",
        "                df = pd.read_csv(file_path)\n",
        "                df[\"ARQUIVO_ORIGEM\"] = file_name\n",
        "                all_dfs.append(df)\n",
        "\n",
        "        if all_dfs:\n",
        "            df_ais = pd.concat(all_dfs, ignore_index=True)\n",
        "            print(f\"‚úÖ AIS carregado de {ais_path}: {df_ais.shape}\")\n",
        "            ais_loaded = True\n",
        "            break\n",
        "\n",
        "if not ais_loaded:\n",
        "    print(\" Arquivo AIS n√£o encontrado em nenhum caminho\")\n",
        "    print(f\"   Tentou: {ais_paths}\")"
      ],
      "metadata": {
        "id": "YT2L8sHoIY10",
        "outputId": "f219e5ed-72dd-4d9a-8646-674b68caab6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Carregando dados de: Hackathon Transpetro/\n",
            " Eventos: (50904, 22)\n",
            " Consumo: (87737, 3)\n",
            " Navios: (21, 8)\n",
            " IWS: (29, 14)\n",
            "‚úÖ AIS carregado de Hackathon Transpetro/Dados AIS frota TP.zip: (415724, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Pr√© Processamento\n"
      ],
      "metadata": {
        "id": "IncmqCwuIiGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padronizar colunas\n",
        "df_eventos.columns = df_eventos.columns.str.strip()\n",
        "df_consumo.columns = df_consumo.columns.str.strip()\n",
        "df_navios.columns = df_navios.columns.str.strip()\n",
        "df_iws.columns = df_iws.columns.str.strip()\n",
        "\n",
        "# Parse datetimes\n",
        "for c in [\"startGMTDate\", \"endGMTDate\"]:\n",
        "    if c in df_eventos.columns:\n",
        "        df_eventos[c] = pd.to_datetime(df_eventos[c], errors='coerce')\n",
        "\n",
        "# Renomear SESSION_ID\n",
        "if \"SESSION_ID\" in df_consumo.columns:\n",
        "    df_consumo.rename(columns={\"SESSION_ID\": \"sessionId\"}, inplace=True)\n",
        "\n",
        "# Processar AIS\n",
        "if not df_ais.empty:\n",
        "    df_ais.columns = df_ais.columns.str.strip()\n",
        "\n",
        "    for cand in [\"DATAHORA\", \"DataHora\", \"datahora\", \"DATETIME\"]:\n",
        "        if cand in df_ais.columns:\n",
        "            df_ais['DATETIME'] = pd.to_datetime(df_ais[cand], errors='coerce')\n",
        "            break\n",
        "\n",
        "    for vcol in [\"VELOCIDADE\", \"speed\", \"SOG\", \"speedGps\"]:\n",
        "        if vcol in df_ais.columns:\n",
        "            df_ais['speed_kn'] = pd.to_numeric(df_ais[vcol], errors='coerce')\n",
        "            break\n",
        "\n",
        "    for cand in [\"NOME\", \"name\", \"ship\", \"shipName\", \"ARQUIVO_ORIGEM\"]:\n",
        "        if cand in df_ais.columns:\n",
        "            df_ais['shipName_ais'] = df_ais[cand].astype(str)\n",
        "            break"
      ],
      "metadata": {
        "id": "YsL3_cPmB6U8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. AGREGA√á√ÉO AIS POR EVENTO"
      ],
      "metadata": {
        "id": "1kwnGG3GGIqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_ais_by_event(df_eventos, df_ais):\n",
        "    \"\"\"Agrega dados AIS para cada evento de navega√ß√£o\"\"\"\n",
        "    agg_rows = []\n",
        "\n",
        "    if df_eventos.empty or df_ais.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df_ais['shipName_ais_low'] = df_ais['shipName_ais'].str.lower().str.strip()\n",
        "    df_eventos['shipName_low'] = df_eventos['shipName'].astype(str).str.lower().str.strip()\n",
        "\n",
        "    ais_groups = {k: g for k, g in df_ais.groupby('shipName_ais_low')}\n",
        "\n",
        "    for idx, ev in tqdm(df_eventos.iterrows(), total=len(df_eventos), desc=\"Agregando AIS\"):\n",
        "        ship = str(ev.get('shipName_low', \"\")).strip()\n",
        "        sdt = ev.get('startGMTDate')\n",
        "        edt = ev.get('endGMTDate')\n",
        "\n",
        "        if ship == \"\" or pd.isna(sdt) or pd.isna(edt):\n",
        "            continue\n",
        "\n",
        "        ais_g = ais_groups.get(ship)\n",
        "        if ais_g is None:\n",
        "            candidates = [k for k in ais_groups.keys() if ship in k or k in ship]\n",
        "            ais_g = ais_groups.get(candidates[0]) if candidates else None\n",
        "\n",
        "        if ais_g is None:\n",
        "            continue\n",
        "\n",
        "        window = ais_g[(ais_g['DATETIME'] >= sdt) & (ais_g['DATETIME'] <= edt)]\n",
        "\n",
        "        if window.empty:\n",
        "            continue\n",
        "\n",
        "        speed_mean = window['speed_kn'].mean()\n",
        "        speed_std = window['speed_kn'].std()\n",
        "        speed_min = window['speed_kn'].min()\n",
        "        speed_max = window['speed_kn'].max()\n",
        "        frac_stop = (window['speed_kn'] < 1.5).mean()\n",
        "        frac_low_speed = (window['speed_kn'] < 5).mean()\n",
        "\n",
        "        lat_mean = pd.to_numeric(window.get('LATITUDE', window.get('latitude', pd.Series(np.nan))), errors='coerce').mean()\n",
        "        lon_mean = pd.to_numeric(window.get('LONGITUDE', window.get('longitude', pd.Series(np.nan))), errors='coerce').mean()\n",
        "\n",
        "        agg_rows.append({\n",
        "            'sessionId': ev.get('sessionId'),\n",
        "            'shipName': ev.get('shipName'),\n",
        "            'startGMTDate': sdt,\n",
        "            'endGMTDate': edt,\n",
        "            'duration_h': ev.get('duration'),\n",
        "            'distance': ev.get('distance'),\n",
        "            'beaufort': ev.get('beaufortScale'),\n",
        "            'seaCondition': ev.get('seaCondition'),\n",
        "            'displacement': ev.get('displacement'),\n",
        "            'speed_mean': speed_mean,\n",
        "            'speed_std': speed_std,\n",
        "            'speed_min': speed_min,\n",
        "            'speed_max': speed_max,\n",
        "            'frac_stop': frac_stop,\n",
        "            'frac_low_speed': frac_low_speed,\n",
        "            'lat_mean': lat_mean,\n",
        "            'lon_mean': lon_mean\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(agg_rows)\n",
        "\n",
        "print(\"\\n Agregando dados AIS...\")\n",
        "df_events_ais = aggregate_ais_by_event(df_eventos, df_ais)\n",
        "print(f\"Eventos com AIS: {df_events_ais.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZaNjnyOFteN",
        "outputId": "90983026-4ef4-4a36-a8d4-31eeb45a0fd7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Agregando dados AIS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Agregando AIS: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50904/50904 [00:44<00:00, 1154.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eventos com AIS: (8214, 17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. FEATURES AVAN√áADAS"
      ],
      "metadata": {
        "id": "SyhZG3B2GMeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_advanced_features(df):\n",
        "    \"\"\"Cria features avan√ßadas baseadas em ci√™ncia de bioincrusta√ß√£o\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1. IDLE TIME FEATURES (CR√çTICO)\n",
        "    df['idle_time_ratio'] = df['frac_stop'].fillna(0)\n",
        "    df['idle_days'] = (df['duration_h'] * df['idle_time_ratio'] / 24).fillna(0)\n",
        "    df['low_speed_days'] = (df['duration_h'] * df['frac_low_speed'] / 24).fillna(0)\n",
        "\n",
        "    # 2. VELOCITY RISK SCORE (CR√çTICO)\n",
        "    def velocity_risk(speed):\n",
        "        if pd.isna(speed):\n",
        "            return 2\n",
        "        if speed < 5:\n",
        "            return 3  # Alto risco\n",
        "        elif speed < 10:\n",
        "            return 2  # Risco moderado\n",
        "        elif speed < 12:\n",
        "            return 1  # Baixo-moderado\n",
        "        else:\n",
        "            return 0  # Baixo risco\n",
        "\n",
        "    df['velocity_risk'] = df['speed_mean'].apply(velocity_risk)\n",
        "\n",
        "    # 3. OPERATIONAL PROFILE\n",
        "    df['operation_continuity'] = 1 - df['idle_time_ratio']\n",
        "\n",
        "    # 4. LOW SHEAR ZONES EXPOSURE\n",
        "    df['low_shear_exposure'] = df['idle_days'] * (df['velocity_risk'] + 1)\n",
        "\n",
        "    # 5. BIOGEOGRAPHIC REGION RISK\n",
        "    def get_biogeographic_region(lat):\n",
        "        if pd.isna(lat):\n",
        "            return 'Unknown'\n",
        "        if lat > -5:\n",
        "            return 'Norte'\n",
        "        elif lat > -15:\n",
        "            return 'Nordeste'\n",
        "        else:\n",
        "            return 'Sudeste-Sul'\n",
        "\n",
        "    df['bio_region'] = df['lat_mean'].apply(get_biogeographic_region)\n",
        "    region_risk = {'Norte': 3, 'Nordeste': 2, 'Sudeste-Sul': 1, 'Unknown': 1.5}\n",
        "    df['region_risk'] = df['bio_region'].map(region_risk)\n",
        "\n",
        "    # 6. TEMPERATURE PROXY\n",
        "    df['temp_proxy'] = df['lat_mean'].abs().fillna(15)\n",
        "    df['temp_risk'] = (15 - df['temp_proxy']).clip(0, 15) / 15\n",
        "\n",
        "    # 7. SPEED VARIABILITY\n",
        "    df['speed_variability'] = df['speed_std'] / (df['speed_mean'] + 1)\n",
        "\n",
        "    return df\n",
        "\n",
        "if not df_events_ais.empty:\n",
        "    df_events_ais = create_advanced_features(df_events_ais)"
      ],
      "metadata": {
        "id": "qwdTQPoAGOTh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. PROCESSAR IWS E CRIAR TARGET"
      ],
      "metadata": {
        "id": "cwhDvCcyGQnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_iws_and_docking_data(df_iws, df_eventos, df_events_ais):\n",
        "    \"\"\"\n",
        "    Processa dados de inspe√ß√£o IWS E eventos de DOCAGEM\n",
        "    para calcular dias desde √∫ltima limpeza\n",
        "    \"\"\"\n",
        "    if df_events_ais.empty:\n",
        "        return df_events_ais\n",
        "\n",
        "    cleaning_events = pd.DataFrame()\n",
        "\n",
        "    # 1. Extrair datas de limpeza do IWS\n",
        "    if not df_iws.empty:\n",
        "        iw_cols = [c for c in df_iws.columns if 'data' in c.lower()]\n",
        "        ship_cols = [c for c in df_iws.columns if 'embarca' in c.lower() or 'navio' in c.lower()]\n",
        "\n",
        "        if iw_cols and ship_cols:\n",
        "            date_col = iw_cols[0]\n",
        "            ship_col = ship_cols[0]\n",
        "\n",
        "            df_iws_clean = df_iws.copy()\n",
        "            df_iws_clean['date_clean'] = pd.to_datetime(df_iws_clean[date_col], errors='coerce')\n",
        "            df_iws_clean['ship_clean'] = df_iws_clean[ship_col].astype(str).str.lower().str.strip()\n",
        "            df_iws_clean['source'] = 'IWS'\n",
        "\n",
        "            cleaning_events = pd.concat([\n",
        "                cleaning_events,\n",
        "                df_iws_clean[['ship_clean', 'date_clean', 'source']].dropna(subset=['date_clean'])\n",
        "            ], ignore_index=True)\n",
        "            print(f\"  {len(df_iws_clean.dropna(subset=['date_clean']))} eventos de limpeza IWS\")\n",
        "\n",
        "    # 2. Extrair datas de DOCAGEM como limpeza\n",
        "    if not df_eventos.empty:\n",
        "        df_docking = df_eventos[df_eventos['eventName'] == 'DOCAGEM'].copy()\n",
        "        if not df_docking.empty:\n",
        "            df_docking['date_clean'] = pd.to_datetime(df_docking['startGMTDate'], errors='coerce')\n",
        "            df_docking['ship_clean'] = df_docking['shipName'].astype(str).str.lower().str.strip()\n",
        "            df_docking['source'] = 'DOCAGEM'\n",
        "\n",
        "            cleaning_events = pd.concat([\n",
        "                cleaning_events,\n",
        "                df_docking[['ship_clean', 'date_clean', 'source']].dropna(subset=['date_clean'])\n",
        "            ], ignore_index=True)\n",
        "            print(f\"  {len(df_docking.dropna(subset=['date_clean']))} eventos de DOCAGEM\")\n",
        "\n",
        "    if cleaning_events.empty:\n",
        "        print(\"Nenhum evento de limpeza encontrado\")\n",
        "        return df_events_ais\n",
        "\n",
        "    # Remover duplicatas e ordenar\n",
        "    cleaning_events = cleaning_events.sort_values('date_clean').drop_duplicates(\n",
        "        subset=['ship_clean', 'date_clean'], keep='first'\n",
        "    )\n",
        "\n",
        "    print(f\"  Total: {len(cleaning_events)} eventos de limpeza combinados\")\n",
        "\n",
        "    # 3. Calcular intervalo mediano por navio\n",
        "    median_interval = cleaning_events.groupby('ship_clean')['date_clean'].apply(\n",
        "        lambda g: g.sort_values().diff().dt.days.median()\n",
        "    ).rename('median_interval').reset_index()\n",
        "    median_interval['median_interval'].fillna(180, inplace=True)\n",
        "\n",
        "    # 4. Calcular dias desde √∫ltima limpeza (IWS ou DOCAGEM)\n",
        "    def days_since_last_clean(row):\n",
        "        s = str(row['shipName']).lower().strip()\n",
        "        start = row['startGMTDate']\n",
        "        if pd.isna(start):\n",
        "            return np.nan, np.nan, 'unknown'\n",
        "\n",
        "        cleans = cleaning_events[\n",
        "            (cleaning_events['ship_clean'] == s) &\n",
        "            (cleaning_events['date_clean'] <= start)\n",
        "        ]\n",
        "\n",
        "        if cleans.empty:\n",
        "            return np.nan, np.nan, 'none'\n",
        "\n",
        "        last_clean_idx = cleans['date_clean'].idxmax()\n",
        "        last_clean = cleans.loc[last_clean_idx]\n",
        "        days = (start - last_clean['date_clean']).days\n",
        "        source = last_clean['source']\n",
        "\n",
        "        median = median_interval[median_interval['ship_clean'] == s]['median_interval']\n",
        "        median_val = median.values[0] if not median.empty else 180\n",
        "\n",
        "        return days, median_val, source\n",
        "\n",
        "    days_list = []\n",
        "    median_list = []\n",
        "    source_list = []\n",
        "\n",
        "    for _, r in tqdm(df_events_ais.iterrows(), total=len(df_events_ais),\n",
        "                     desc=\"Calculando dias desde limpeza\"):\n",
        "        d, med, src = days_since_last_clean(r)\n",
        "        days_list.append(d)\n",
        "        median_list.append(med)\n",
        "        source_list.append(src)\n",
        "\n",
        "    df_events_ais['days_since_clean'] = days_list\n",
        "    df_events_ais['median_interval'] = median_list\n",
        "    df_events_ais['clean_source'] = source_list\n",
        "\n",
        "    # Estat√≠sticas\n",
        "    source_counts = pd.Series(source_list).value_counts()\n",
        "    print(f\"\\n  Origem da √∫ltima limpeza:\")\n",
        "    for src, count in source_counts.items():\n",
        "        print(f\"    {src}: {count} eventos\")\n",
        "\n",
        "    return df_events_ais\n",
        "\n",
        "def create_fouling_percentage_target(df):\n",
        "    \"\"\"\n",
        "    Cria target baseado em PORCENTAGEM de incrusta√ß√£o no casco (0-100%)\n",
        "\n",
        "    A porcentagem representa a √°rea do casco coberta por bioincrusta√ß√£o.\n",
        "    Depois converte para escala IMO apenas para refer√™ncia visual.\n",
        "\n",
        "    Escala IMO MEPC.378(80) (apenas refer√™ncia):\n",
        "    0: Sem bioincrusta√ß√£o (0%)\n",
        "    1: Microincrusta√ß√£o (biofilme/limo) (0-1%)\n",
        "    2: Macroincrusta√ß√£o leve (1-15%)\n",
        "    3: Macroincrusta√ß√£o moderada (16-40%)\n",
        "    4: Macroincrusta√ß√£o pesada (41-100%)\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    def estimate_fouling_percentage(row):\n",
        "        \"\"\"Estima porcentagem de √°rea do casco com incrusta√ß√£o\"\"\"\n",
        "        days = row.get('days_since_clean', np.nan)\n",
        "        velocity_risk = row.get('velocity_risk', 2)\n",
        "        idle_ratio = row.get('idle_time_ratio', 0)\n",
        "        temp_risk = row.get('temp_risk', 0.5)\n",
        "        region_risk = row.get('region_risk', 1.5)\n",
        "\n",
        "        if pd.isna(days):\n",
        "            return np.nan\n",
        "\n",
        "        # Base de crescimento por tempo (em porcentagem)\n",
        "        # Crescimento exponencial nos primeiros dias, depois linear\n",
        "        if days < 14:\n",
        "            base_pct = 0.5  # Biofilme inicial\n",
        "        elif days < 42:\n",
        "            base_pct = 2.0 + (days - 14) * 0.15  # Crescimento acelerado\n",
        "        elif days < 90:\n",
        "            base_pct = 6.2 + (days - 42) * 0.25  # Crescimento moderado\n",
        "        elif days < 180:\n",
        "            base_pct = 18.2 + (days - 90) * 0.22  # Crescimento cont√≠nuo\n",
        "        elif days < 365:\n",
        "            base_pct = 38.0 + (days - 180) * 0.15  # Crescimento desacelerando\n",
        "        else:\n",
        "            base_pct = 65.75 + (days - 365) * 0.08  # Crescimento lento\n",
        "\n",
        "        # Modificadores baseados em condi√ß√µes operacionais\n",
        "        velocity_modifier = velocity_risk * 3.5  # Alto impacto da velocidade\n",
        "        idle_modifier = idle_ratio * 12.0  # Tempo parado acelera muito\n",
        "        temp_modifier = temp_risk * 8.0  # Temperatura favorece crescimento\n",
        "        region_modifier = (region_risk - 1.5) * 5.0  # Regi√£o biogeogr√°fica\n",
        "\n",
        "        final_pct = base_pct + velocity_modifier + idle_modifier + temp_modifier + region_modifier\n",
        "\n",
        "        return np.clip(final_pct, 0, 100)\n",
        "\n",
        "    df['fouling_percentage'] = df.apply(estimate_fouling_percentage, axis=1)\n",
        "\n",
        "    # Converter porcentagem para escala IMO (apenas para refer√™ncia)\n",
        "    def percentage_to_imo_rating(pct):\n",
        "        \"\"\"Converte porcentagem para escala IMO\"\"\"\n",
        "        if pd.isna(pct):\n",
        "            return np.nan\n",
        "        if pct < 0.5:\n",
        "            return 0.0  # Sem incrusta√ß√£o\n",
        "        elif pct < 1.0:\n",
        "            return 0.5 + (pct - 0.5)  # Transi√ß√£o para micro\n",
        "        elif pct < 15.0:\n",
        "            return 1.0 + (pct - 1.0) / 14.0  # Microincrusta√ß√£o\n",
        "        elif pct < 40.0:\n",
        "            return 2.0 + (pct - 15.0) / 25.0  # Leve\n",
        "        elif pct < 70.0:\n",
        "            return 3.0 + (pct - 40.0) / 30.0  # Moderada\n",
        "        else:\n",
        "            return 4.0  # Pesada\n",
        "\n",
        "    df['fouling_rating_imo'] = df['fouling_percentage'].apply(percentage_to_imo_rating)\n",
        "\n",
        "    # Criar est√°gios baseados em porcentagem\n",
        "    def get_fouling_stage_from_pct(pct):\n",
        "        if pd.isna(pct):\n",
        "            return np.nan\n",
        "        if pct < 1.0:\n",
        "            return 0  # Limpo/Micro\n",
        "        elif pct < 15.0:\n",
        "            return 1  # Leve\n",
        "        elif pct < 40.0:\n",
        "            return 2  # Moderado\n",
        "        else:\n",
        "            return 3  # Pesado\n",
        "\n",
        "    df['fouling_stage'] = df['fouling_percentage'].apply(get_fouling_stage_from_pct)\n",
        "\n",
        "    # Labels categ√≥ricos baseados em porcentagem\n",
        "    def get_fouling_label_from_pct(pct):\n",
        "        if pd.isna(pct):\n",
        "            return np.nan\n",
        "        if pct < 1.0:\n",
        "            return 'clean'\n",
        "        elif pct < 15.0:\n",
        "            return 'light'\n",
        "        elif pct < 40.0:\n",
        "            return 'moderate'\n",
        "        else:\n",
        "            return 'heavy'\n",
        "\n",
        "    df['fouling_label'] = df['fouling_percentage'].apply(get_fouling_label_from_pct)\n",
        "\n",
        "    # Risk score combinado (mantido para compatibilidade)\n",
        "    df['biofouling_risk_score'] = (\n",
        "        0.4 * (df['days_since_clean'].fillna(90) / 180).clip(0, 1) +\n",
        "        0.25 * (df['velocity_risk'] / 3) +\n",
        "        0.2 * df['idle_time_ratio'] +\n",
        "        0.15 * df['temp_risk']\n",
        "    ).clip(0, 1)\n",
        "\n",
        "    print(\"Target de Porcentagem de Fouling criado!\")\n",
        "    print(f\"\\nDistribui√ß√£o de Porcentagem de Incrusta√ß√£o:\")\n",
        "    print(df['fouling_percentage'].describe())\n",
        "    print(f\"\\nDistribui√ß√£o de Rating IMO (refer√™ncia):\")\n",
        "    print(df['fouling_rating_imo'].describe())\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\"\\n Processando IWS, DOCAGEM e criando target...\")\n",
        "if not df_events_ais.empty:\n",
        "    df_events_ais = process_iws_and_docking_data(df_iws, df_eventos, df_events_ais)\n",
        "    df_events_ais = create_fouling_percentage_target(df_events_ais)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksQelerXGRJb",
        "outputId": "533bbc3f-cb33-44f3-bdf3-983b1efd41fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Processando IWS, DOCAGEM e criando target...\n",
            "  28 eventos de limpeza IWS\n",
            "  152 eventos de DOCAGEM\n",
            "  Total: 180 eventos de limpeza combinados\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando dias desde limpeza: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8214/8214 [00:07<00:00, 1108.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Origem da √∫ltima limpeza:\n",
            "    DOCAGEM: 4738 eventos\n",
            "    IWS: 2627 eventos\n",
            "    none: 849 eventos\n",
            "Target de Porcentagem de Fouling criado!\n",
            "\n",
            "Distribui√ß√£o de Porcentagem de Incrusta√ß√£o:\n",
            "count    7365.000000\n",
            "mean       71.844837\n",
            "std        28.813374\n",
            "min         0.000000\n",
            "25%        50.544110\n",
            "50%        80.301049\n",
            "75%       100.000000\n",
            "max       100.000000\n",
            "Name: fouling_percentage, dtype: float64\n",
            "\n",
            "Distribui√ß√£o de Rating IMO (refer√™ncia):\n",
            "count    7365.000000\n",
            "mean        3.582217\n",
            "std         0.705288\n",
            "min         0.000000\n",
            "25%         3.351470\n",
            "50%         4.000000\n",
            "75%         4.000000\n",
            "max         4.000000\n",
            "Name: fouling_rating_imo, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. MERGE COM CONSUMO E NAVIOS"
      ],
      "metadata": {
        "id": "InxOT-k8GSpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîó Merging dados...\")\n",
        "if not df_events_ais.empty and 'sessionId' in df_consumo.columns:\n",
        "    df_cons_sum = df_consumo.groupby('sessionId', as_index=False)['CONSUMED_QUANTITY'].sum()\n",
        "    df_events_ais = df_events_ais.merge(df_cons_sum, on='sessionId', how='left')\n",
        "\n",
        "if not df_events_ais.empty and not df_navios.empty:\n",
        "    shipname_col = [c for c in df_navios.columns if 'nome' in c.lower() or 'name' in c.lower()]\n",
        "    if shipname_col:\n",
        "        snc = shipname_col[0]\n",
        "        df_navios['ship_nav_low'] = df_navios[snc].astype(str).str.lower().str.strip()\n",
        "        df_events_ais['ship_low'] = df_events_ais['shipName'].astype(str).str.lower().str.strip()\n",
        "        df_events_ais = df_events_ais.merge(df_navios, left_on='ship_low', right_on='ship_nav_low', how='left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ORalsCGUX6",
        "outputId": "7766b23c-cbbf-4f81-e515-15c9986b46b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîó Merging dados...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. PREPARAR DATASET ML"
      ],
      "metadata": {
        "id": "nSOn3ob_GXbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_v2 = [\n",
        "    'speed_mean', 'speed_std', 'speed_min', 'speed_max',\n",
        "    'duration_h', 'distance',\n",
        "    'frac_stop', 'frac_low_speed', 'idle_days', 'low_speed_days',\n",
        "    'velocity_risk', 'operation_continuity', 'speed_variability',\n",
        "    'low_shear_exposure', 'biofouling_risk_score',\n",
        "    'beaufort', 'seaCondition', 'lat_mean', 'lon_mean',\n",
        "    'temp_proxy', 'temp_risk', 'region_risk',\n",
        "    'days_since_clean', 'fouling_stage',\n",
        "    'displacement'\n",
        "]\n",
        "\n",
        "if 'CONSUMED_QUANTITY' in df_events_ais.columns:\n",
        "    features_v2.append('CONSUMED_QUANTITY')\n",
        "\n",
        "features_available = [f for f in features_v2 if f in df_events_ais.columns]\n",
        "\n",
        "print(f\"\\nüìä Features dispon√≠veis: {len(features_available)}\")\n",
        "\n",
        "df_ml = df_events_ais.dropna(subset=['fouling_percentage'])[features_available + ['fouling_percentage', 'fouling_rating_imo', 'fouling_label', 'startGMTDate', 'shipName']].copy()\n",
        "df_ml[features_available] = df_ml[features_available].fillna(0)\n",
        "\n",
        "print(f\"‚úÖ Dataset ML: {df_ml.shape}\")\n",
        "print(f\"   Target: Porcentagem de Incrusta√ß√£o (0-100%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwCI3oFQGZ1d",
        "outputId": "359db012-e2a7-4f98-8406-bc300395a96b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Features dispon√≠veis: 26\n",
            "‚úÖ Dataset ML: (7365, 31)\n",
            "   Target: Porcentagem de Incrusta√ß√£o (0-100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.  VALIDA√á√ÉO TEMPORAL"
      ],
      "metadata": {
        "id": "qJL-RSM7Gcpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml_sorted = df_ml.sort_values('startGMTDate').reset_index(drop=True)\n",
        "\n",
        "X = df_ml_sorted[features_available].values\n",
        "y_reg = df_ml_sorted['fouling_percentage'].values  # Target principal: porcentagem\n",
        "y_imo = df_ml_sorted['fouling_rating_imo'].values  # Refer√™ncia IMO\n",
        "y_clf = LabelEncoder().fit_transform(df_ml_sorted['fouling_label'].astype(str).values)\n",
        "\n",
        "split_idx = int(len(df_ml_sorted) * 0.8)\n",
        "\n",
        "X_train = X[:split_idx]\n",
        "X_test = X[split_idx:]\n",
        "y_train = y_reg[:split_idx]\n",
        "y_test = y_reg[split_idx:]\n",
        "\n",
        "print(f\"‚úÖ Treino: {X_train.shape[0]} | Teste: {X_test.shape[0]}\")\n",
        "print(f\"   Target: Porcentagem de Incrusta√ß√£o (0-100%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQrbdzB8GeZB",
        "outputId": "01613416-67b4-4535-8213-0d7a9965e7fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Treino: 5892 | Teste: 1473\n",
            "   Target: Porcentagem de Incrusta√ß√£o (0-100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. üéØ MODELO ENSEMBLE"
      ],
      "metadata": {
        "id": "Pro-cMHgGfIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Treinando ensemble...\")\n",
        "\n",
        "models = {\n",
        "    'XGBoost': xgb.XGBRegressor(\n",
        "        n_estimators=300, learning_rate=0.03, max_depth=6,\n",
        "        subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0\n",
        "    ),\n",
        "    'LightGBM': lgb.LGBMRegressor(\n",
        "        n_estimators=300, learning_rate=0.03, max_depth=6,\n",
        "        random_state=42, verbosity=-1\n",
        "    ),\n",
        "    'RandomForest': RandomForestRegressor(\n",
        "        n_estimators=200, max_depth=10, random_state=42, n_jobs=-1\n",
        "    ),\n",
        "    'GradientBoosting': GradientBoostingRegressor(\n",
        "        n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "predictions = {}\n",
        "model_scores = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTreinando {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions[name] = y_pred\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    model_scores[name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
        "    print(f\"  MAE: {mae:.4f} | RMSE: {rmse:.4f} | R¬≤: {r2:.4f}\")\n",
        "\n",
        "# Ensemble com pesos\n",
        "maes = [model_scores[name]['MAE'] for name in models.keys()]\n",
        "weights = [1/mae for mae in maes]\n",
        "weights = [w/sum(weights) for w in weights]\n",
        "\n",
        "y_pred_ensemble = sum(predictions[name] * weight for name, weight in zip(models.keys(), weights))\n",
        "\n",
        "mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
        "rmse_ensemble = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))\n",
        "r2_ensemble = r2_score(y_test, y_pred_ensemble)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\" ENSEMBLE:\")\n",
        "print(f\"  MAE: {mae_ensemble:.4f}\")\n",
        "print(f\"  RMSE: {rmse_ensemble:.4f}\")\n",
        "print(f\"  R¬≤: {r2_ensemble:.4f}\")\n",
        "print(f\"{'='*60}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUtbv02GGhBH",
        "outputId": "e8d911c9-75e9-452e-ad39-b81286b59bbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Treinando ensemble...\n",
            "\n",
            "Treinando XGBoost...\n",
            "  MAE: 0.4822 | RMSE: 0.7648 | R¬≤: 0.9995\n",
            "\n",
            "Treinando LightGBM...\n",
            "  MAE: 0.4512 | RMSE: 0.7206 | R¬≤: 0.9995\n",
            "\n",
            "Treinando RandomForest...\n",
            "  MAE: 0.5541 | RMSE: 0.9892 | R¬≤: 0.9992\n",
            "\n",
            "Treinando GradientBoosting...\n",
            "  MAE: 0.5325 | RMSE: 0.8056 | R¬≤: 0.9994\n",
            "\n",
            "============================================================\n",
            " ENSEMBLE:\n",
            "  MAE: 0.4400\n",
            "  RMSE: 0.7133\n",
            "  R¬≤: 0.9996\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.  IMPACTO ECON√îMICO\n"
      ],
      "metadata": {
        "id": "tSHySJaeGj6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_fuel_penalty_from_fouling(fouling_percentage, baseline_consumption):\n",
        "    \"\"\"\n",
        "    Calcula penalidade de combust√≠vel baseado na PORCENTAGEM de incrusta√ß√£o\n",
        "\n",
        "    Baseado em estudos cient√≠ficos:\n",
        "    - 0-1%: Biofilme inicial, penalidade m√≠nima (0-5%)\n",
        "    - 1-15%: Macroincrusta√ß√£o leve (5-10%)\n",
        "    - 15-40%: Macroincrusta√ß√£o moderada (10-18%)\n",
        "    - 40-70%: Macroincrusta√ß√£o pesada (18-25%)\n",
        "    - 70-100%: Macroincrusta√ß√£o cr√≠tica (25-35%)\n",
        "    \"\"\"\n",
        "    PRICE_PER_TON = 650\n",
        "    CO2_PER_TON = 3.114\n",
        "\n",
        "    # Calcular penalidade baseada em porcentagem de incrusta√ß√£o\n",
        "    if fouling_percentage < 0.5:\n",
        "        penalty = 0.0\n",
        "    elif fouling_percentage < 1.0:\n",
        "        # Biofilme inicial: 0-5%\n",
        "        penalty = 0.05 * (fouling_percentage / 1.0)\n",
        "    elif fouling_percentage < 15.0:\n",
        "        # Leve: 5-10%\n",
        "        penalty = 0.05 + 0.05 * ((fouling_percentage - 1.0) / 14.0)\n",
        "    elif fouling_percentage < 40.0:\n",
        "        # Moderada: 10-18%\n",
        "        penalty = 0.10 + 0.08 * ((fouling_percentage - 15.0) / 25.0)\n",
        "    elif fouling_percentage < 70.0:\n",
        "        # Pesada: 18-25%\n",
        "        penalty = 0.18 + 0.07 * ((fouling_percentage - 40.0) / 30.0)\n",
        "    else:\n",
        "        # Cr√≠tica: 25-35%\n",
        "        penalty = 0.25 + 0.10 * min((fouling_percentage - 70.0) / 30.0, 1.0)\n",
        "\n",
        "    extra_fuel = baseline_consumption * penalty\n",
        "\n",
        "    return {\n",
        "        'fouling_percentage': fouling_percentage,\n",
        "        'fuel_penalty_pct': penalty * 100,\n",
        "        'extra_fuel_tons_day': extra_fuel,\n",
        "        'extra_cost_usd_day': extra_fuel * PRICE_PER_TON,\n",
        "        'extra_cost_usd_month': extra_fuel * PRICE_PER_TON * 30,\n",
        "        'extra_cost_usd_year': extra_fuel * PRICE_PER_TON * 365,\n",
        "        'extra_co2_tons_year': extra_fuel * CO2_PER_TON * 365\n",
        "    }\n",
        "\n",
        "print(\"\\n Calculando impacto econ√¥mico...\")\n",
        "baseline = 40\n",
        "all_impacts = [compute_fuel_penalty_from_fouling(pred, baseline) for pred in y_pred_ensemble]\n",
        "df_impacts = pd.DataFrame(all_impacts)\n",
        "\n",
        "print(f\"Custo Extra M√©dio/Dia: ${df_impacts['extra_cost_usd_day'].mean():,.2f}\")\n",
        "print(f\"Custo Extra M√©dio/M√™s: ${df_impacts['extra_cost_usd_month'].mean():,.2f}\")\n",
        "print(f\"Custo Extra M√©dio/Ano: ${df_impacts['extra_cost_usd_year'].mean():,.2f}\")\n",
        "print(f\"CO2 Extra M√©dio/Ano: {df_impacts['extra_co2_tons_year'].mean():,.2f} tons\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ycll8oKGljD",
        "outputId": "7aa7bbbd-7d08-4015-adbe-5a4b90eeaad7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Calculando impacto econ√¥mico...\n",
            "Custo Extra M√©dio/Dia: $6,607.33\n",
            "Custo Extra M√©dio/M√™s: $198,219.84\n",
            "Custo Extra M√©dio/Ano: $2,411,674.76\n",
            "CO2 Extra M√©dio/Ano: 11,553.78 tons\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.  AN√ÅLISE DE CEN√ÅRIOS"
      ],
      "metadata": {
        "id": "D7HNMXPgGnWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_cleaning_scenarios(current_fouling_pct, days_since_clean, baseline=40):\n",
        "    \"\"\"\n",
        "    Simula cen√°rios de limpeza baseado em porcentagem de incrusta√ß√£o\n",
        "\n",
        "    Args:\n",
        "        current_fouling_pct: Porcentagem atual de incrusta√ß√£o (0-100%)\n",
        "        days_since_clean: Dias desde √∫ltima limpeza\n",
        "        baseline: Consumo base em tons/dia\n",
        "    \"\"\"\n",
        "    CLEANING_COST = 50000\n",
        "    DOWNTIME_COST = 24 * 5000\n",
        "    DAYS_AHEAD = 180\n",
        "\n",
        "    scenarios = {}\n",
        "\n",
        "    # Cen√°rio 1: N√£o fazer nada\n",
        "    # Crescimento estimado: ~0.15% por dia em condi√ß√µes normais\n",
        "    growth_rate = 0.15\n",
        "    future_fouling_pct = min(current_fouling_pct + (DAYS_AHEAD * growth_rate), 100.0)\n",
        "\n",
        "    current_impact = compute_fuel_penalty_from_fouling(current_fouling_pct, baseline)\n",
        "    future_impact = compute_fuel_penalty_from_fouling(future_fouling_pct, baseline)\n",
        "    avg_cost = (current_impact['extra_cost_usd_day'] + future_impact['extra_cost_usd_day']) / 2\n",
        "\n",
        "    scenarios['N√£o Fazer Limpeza'] = {\n",
        "        'total_cost': avg_cost * DAYS_AHEAD,\n",
        "        'final_fouling_pct': future_fouling_pct,\n",
        "        'final_fouling_desc': f\"{future_fouling_pct:.1f}%\"\n",
        "    }\n",
        "\n",
        "    # Cen√°rio 2: Limpar agora\n",
        "    post_clean_pct = 0.5  # Ap√≥s limpeza: ~0.5%\n",
        "    future_clean_pct = min(post_clean_pct + (DAYS_AHEAD * growth_rate * 0.8), 30.0)  # Crescimento mais lento\n",
        "\n",
        "    post_impact = compute_fuel_penalty_from_fouling(post_clean_pct, baseline)\n",
        "    future_impact_clean = compute_fuel_penalty_from_fouling(future_clean_pct, baseline)\n",
        "    avg_cost_clean = (post_impact['extra_cost_usd_day'] + future_impact_clean['extra_cost_usd_day']) / 2\n",
        "\n",
        "    scenarios['Fazer Limpeza'] = {\n",
        "        'total_cost': CLEANING_COST + DOWNTIME_COST + (avg_cost_clean * DAYS_AHEAD),\n",
        "        'final_fouling_pct': future_clean_pct,\n",
        "        'final_fouling_desc': f\"{future_clean_pct:.1f}%\"\n",
        "    }\n",
        "\n",
        "    return scenarios\n",
        "\n",
        "print(\"\\n Simulando cen√°rios...\")\n",
        "example_fouling_pct = y_pred_ensemble[0]\n",
        "example_days = df_ml_sorted.iloc[split_idx]['days_since_clean']\n",
        "\n",
        "scenarios = simulate_cleaning_scenarios(example_fouling_pct, example_days)\n",
        "\n",
        "print(f\"\\nIncrusta√ß√£o atual: {example_fouling_pct:.1f}%\")\n",
        "for name, data in scenarios.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Custo total: ${data['total_cost']:,.2f}\")\n",
        "    print(f\"  Incrusta√ß√£o final: {data['final_fouling_desc']}\")\n",
        "\n",
        "best = min(scenarios.items(), key=lambda x: x[1]['total_cost'])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNWnuMzpGp4K",
        "outputId": "3842c281-ea4c-48a4-d91e-b5a3d4f613dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Simulando cen√°rios...\n",
            "\n",
            "Incrusta√ß√£o atual: 64.4%\n",
            "\n",
            "N√£o Fazer Limpeza:\n",
            "  Custo total: $1,305,865.93\n",
            "  Incrusta√ß√£o final: 91.4%\n",
            "\n",
            "Fazer Limpeza:\n",
            "  Custo total: $515,664.80\n",
            "  Incrusta√ß√£o final: 22.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. SALVAR MODELOS"
      ],
      "metadata": {
        "id": "II3NxQFkGqvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Salvando modelos...\")\n",
        "for name, model in models.items():\n",
        "    filename = f\"model_{name.lower().replace(' ', '_')}_v2.pkl\"\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "metadata = {\n",
        "    'features': features_available,\n",
        "    'weights': dict(zip(models.keys(), weights)),\n",
        "    'mae': mae_ensemble,\n",
        "    'rmse': rmse_ensemble,\n",
        "    'r2': r2_ensemble\n",
        "}\n",
        "\n",
        "with open('model_metadata_v2.pkl', 'wb') as f:\n",
        "    pickle.dump(metadata, f)\n",
        "\n",
        "print(\" Modelos salvos\")\n",
        "\n",
        "# 13. RESUMO\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMO SOLU√á√ÉO DE PREDI√á√ÉO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n PERFORMANCE:\")\n",
        "print(f\"  MAE:  {mae_ensemble:.4f}\")\n",
        "print(f\"  RMSE: {rmse_ensemble:.4f}\")\n",
        "print(f\"  R¬≤:   {r2_ensemble:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLtb_kJzGtVL",
        "outputId": "26c4191d-5e46-4a8f-bb99-b6d634636336"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Salvando modelos...\n",
            " Modelos salvos\n",
            "\n",
            "================================================================================\n",
            " RESUMO SOLU√á√ÉO DE PREDI√á√ÉO\n",
            "================================================================================\n",
            "\n",
            " PERFORMANCE:\n",
            "  MAE:  0.4400\n",
            "  RMSE: 0.7133\n",
            "  R¬≤:   0.9996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. FOULING RATING POR NAVIO (FROTA)"
      ],
      "metadata": {
        "id": "lV9t7e6hGwWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_header(\"AN√ÅLISE DA FROTA\")\n",
        "\n",
        "# Pegar √∫ltimo evento de cada navio\n",
        "df_ml_sorted_final = df_ml_sorted.copy()\n",
        "\n",
        "# Verificar se shipName existe, sen√£o usar √≠ndice\n",
        "if 'shipName' not in df_ml_sorted_final.columns:\n",
        "    # Adicionar shipName do df_ml original\n",
        "    df_ml_sorted_final = df_ml_sorted_final.merge(\n",
        "        df_ml[['startGMTDate', 'shipName']],\n",
        "        on='startGMTDate',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "df_ml_sorted_final['shipName_clean'] = df_ml_sorted_final['shipName'].astype(str).str.strip()\n",
        "\n",
        "# √öltimo evento de cada navio (mais recente)\n",
        "ultimos_eventos = df_ml_sorted_final.groupby('shipName_clean').last().reset_index()\n",
        "\n",
        "# Calcular impacto econ√¥mico para cada navio\n",
        "resultados_frota = []\n",
        "\n",
        "for _, navio_data in ultimos_eventos.iterrows():\n",
        "    ship_name = navio_data['shipName_clean']\n",
        "    fouling_pct = navio_data['fouling_percentage']\n",
        "    fouling_imo = navio_data.get('fouling_rating_imo', np.nan)\n",
        "    days_clean = navio_data.get('days_since_clean', np.nan)\n",
        "\n",
        "    # Calcular impacto\n",
        "    baseline = 40  # tons/dia (ajustar se tiver dados espec√≠ficos)\n",
        "    impacto = compute_fuel_penalty_from_fouling(fouling_pct, baseline)\n",
        "\n",
        "    # Classificar por porcentagem\n",
        "    if fouling_pct < 1.0:\n",
        "        classificacao = \"Limpo\"\n",
        "        acao = \"OK\"\n",
        "    elif fouling_pct < 15.0:\n",
        "        classificacao = \"Leve\"\n",
        "        acao = \"Monitorar\"\n",
        "    elif fouling_pct < 40.0:\n",
        "        classificacao = \"Moderada\"\n",
        "        acao = \"Recomendada\"\n",
        "    elif fouling_pct < 70.0:\n",
        "        classificacao = \"Pesada\"\n",
        "        acao = \"Urgente\"\n",
        "    else:\n",
        "        classificacao = \"Cr√≠tica\"\n",
        "        acao = \"Imediata\"\n",
        "\n",
        "    resultados_frota.append({\n",
        "        'Navio': ship_name,\n",
        "        'Incrust.%': round(fouling_pct, 1),\n",
        "        'IMO': round(fouling_imo, 2) if not pd.isna(fouling_imo) else 'N/A',\n",
        "        'Status': classificacao,\n",
        "        'Dias': int(days_clean) if not pd.isna(days_clean) else 'N/A',\n",
        "        'Penalidade': f\"{impacto['fuel_penalty_pct']:.1f}%\",\n",
        "        'Custo/Ano': f\"${impacto['extra_cost_usd_year']/1e6:.2f}M\",\n",
        "        'CO2/Ano': f\"{impacto['extra_co2_tons_year']/1e3:.1f}kt\",\n",
        "        'A√ß√£o': acao\n",
        "    })\n",
        "\n",
        "df_frota = pd.DataFrame(resultados_frota)\n",
        "\n",
        "# Ordenar por Porcentagem de Incrusta√ß√£o (maior primeiro)\n",
        "df_frota = df_frota.sort_values('Incrust.%', ascending=False)\n",
        "\n",
        "# Imprimir tabela\n",
        "if RICH_AVAILABLE:\n",
        "    table = Table(title=\"Condi√ß√£o da Frota\", box=box.SIMPLE_HEAD, show_header=True, header_style=\"bold cyan\")\n",
        "\n",
        "    for col in df_frota.columns:\n",
        "        justify = \"right\" if col in ['Incrust.%', 'IMO', 'Dias', 'Penalidade'] else \"left\"\n",
        "        table.add_column(col, justify=justify)\n",
        "\n",
        "    for _, row in df_frota.iterrows():\n",
        "        # Colorir baseado na classifica√ß√£o\n",
        "        status = row['Status']\n",
        "        if status == 'Cr√≠tica':\n",
        "            style = \"bold red\"\n",
        "        elif status == 'Pesada':\n",
        "            style = \"red\"\n",
        "        elif status == 'Moderada':\n",
        "            style = \"yellow\"\n",
        "        elif status == 'Leve':\n",
        "            style = \"blue\"\n",
        "        else:\n",
        "            style = \"green\"\n",
        "\n",
        "        table.add_row(*[str(val) for val in row], style=style)\n",
        "\n",
        "    console.print(table)\n",
        "else:\n",
        "    print(\"\\n\" + df_frota.to_string(index=False))\n",
        "\n",
        "# Estat√≠sticas da frota\n",
        "print_header(\"ESTAT√çSTICAS DA FROTA\")\n",
        "\n",
        "fouling_pct_values = df_frota['Incrust.%'].values\n",
        "\n",
        "# Distribui√ß√£o por categoria (baseada em porcentagem)\n",
        "clean_count = (fouling_pct_values < 1.0).sum()\n",
        "leve_count = ((fouling_pct_values >= 1.0) & (fouling_pct_values < 15.0)).sum()\n",
        "moderada_count = ((fouling_pct_values >= 15.0) & (fouling_pct_values < 40.0)).sum()\n",
        "pesada_count = ((fouling_pct_values >= 40.0) & (fouling_pct_values < 70.0)).sum()\n",
        "critica_count = (fouling_pct_values >= 70.0).sum()\n",
        "\n",
        "total_navios = len(fouling_pct_values)\n",
        "\n",
        "print_info(f\"\\nDistribui√ß√£o:\")\n",
        "print_info(f\"  Limpo (0-1%):     {clean_count:2d} navios ({clean_count/total_navios*100:5.1f}%)\")\n",
        "print_info(f\"  Leve (1-15%):     {leve_count:2d} navios ({leve_count/total_navios*100:5.1f}%)\")\n",
        "print_info(f\"  Moderada (15-40%): {moderada_count:2d} navios ({moderada_count/total_navios*100:5.1f}%)\")\n",
        "print_info(f\"  Pesada (40-70%):   {pesada_count:2d} navios ({pesada_count/total_navios*100:5.1f}%)\")\n",
        "print_info(f\"  Cr√≠tica (70-100%): {critica_count:2d} navios ({critica_count/total_navios*100:5.1f}%)\")\n",
        "\n",
        "# Prioriza√ß√£o de a√ß√µes\n",
        "urgente_count = (fouling_pct_values >= 40.0).sum()\n",
        "recomendada_count = ((fouling_pct_values >= 15.0) & (fouling_pct_values < 40.0)).sum()\n",
        "monitorar_count = ((fouling_pct_values >= 1.0) & (fouling_pct_values < 15.0)).sum()\n",
        "critica_count_frota = critica_count  # Salvar para compara√ß√£o na valida√ß√£o\n",
        "\n",
        "print_info(f\"\\nA√ß√µes Requeridas:\")\n",
        "if urgente_count > 0:\n",
        "    print_warning(f\"{urgente_count} navios requerem limpeza urgente (‚â•40%)\")\n",
        "if recomendada_count > 0:\n",
        "    print_info(f\"  {recomendada_count} navios requerem limpeza recomendada (15-40%)\")\n",
        "if monitorar_count > 0:\n",
        "    print_info(f\"  {monitorar_count} navios requerem monitoramento (1-15%)\")\n",
        "\n",
        "# Impacto econ√¥mico total\n",
        "custo_ano_values = df_frota['Custo/Ano'].str.replace('$', '').str.replace('M', '').astype(float) * 1e6\n",
        "co2_ano_values = df_frota['CO2/Ano'].str.replace('kt', '').astype(float) * 1e3\n",
        "\n",
        "total_custo = custo_ano_values.sum()\n",
        "total_co2 = co2_ano_values.sum()\n",
        "\n",
        "print_info(f\"\\nImpacto Econ√¥mico Total:\")\n",
        "print_info(f\"  Custo Extra/Ano: ${total_custo/1e6:.2f}M | M√©dio/Navio: ${total_custo/total_navios/1e6:.2f}M\")\n",
        "print_info(f\"  CO2 Extra/Ano: {total_co2/1e3:.1f}kt | M√©dio/Navio: {total_co2/total_navios/1e3:.1f}kt\")\n",
        "\n",
        "# Salvar resultados detalhados\n",
        "df_frota.to_csv('fouling_por_navio.csv', index=False)\n",
        "print_success(\"Resultados salvos em: fouling_por_navio.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "b0dmFo_8Gw-P",
        "outputId": "32b1c6d4-b19f-438f-8250-37a61d498a7d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36mAN√ÅLISE DA FROTA\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">AN√ÅLISE DA FROTA</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                             Condi√ß√£o da Frota                                             \u001b[0m\n",
              "                                                                                                           \n",
              " \u001b[1;36m \u001b[0m\u001b[1;36mNavio            \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mIncrust.%\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36m IMO\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mStatus  \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mDias\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mPenalidade\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mCusto/Ano\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mCO2/Ano\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mA√ß√£o       \u001b[0m\u001b[1;36m \u001b[0m \n",
              " ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mBRUNO LIMA       \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 565\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mDANIEL PEREIRA   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 771\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mVICTOR OLIVEIRA  \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 915\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mMARCOS CAVALCANTI\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 666\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mGABRIELA MARTINS \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     81.9\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 598\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     29.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$2.75M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m13.2kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mMARIA VALENTINA  \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     73.5\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 374\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     26.2%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$2.48M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m11.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mFELIPE RIBEIRO   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     72.3\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 478\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     25.8%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$2.44M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m11.7kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mRODRIGO PINHEIRO \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     70.8\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 460\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     25.3%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$2.40M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m11.5kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata   \u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[31m \u001b[0m\u001b[31mEDUARDO COSTA    \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m     50.1\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m3.34\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31mPesada  \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m 181\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m     20.4%\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m$1.93M   \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m9.3kt  \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31mUrgente    \u001b[0m\u001b[31m \u001b[0m \n",
              " \u001b[31m \u001b[0m\u001b[31mGISELLE CARVALHO \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m     45.5\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m3.19\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31mPesada  \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m 247\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m     19.3%\u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m$1.83M   \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31m8.8kt  \u001b[0m\u001b[31m \u001b[0m \u001b[31m \u001b[0m\u001b[31mUrgente    \u001b[0m\u001b[31m \u001b[0m \n",
              " \u001b[33m \u001b[0m\u001b[33mTHIAGO FERNANDES \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     34.7\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m2.79\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mModerada\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m  42\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     16.3%\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m$1.55M   \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m7.4kt  \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mRecomendada\u001b[0m\u001b[33m \u001b[0m \n",
              " \u001b[33m \u001b[0m\u001b[33mRAUL MARTINS     \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     32.0\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m2.68\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mModerada\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m 148\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     15.4%\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m$1.46M   \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m7.0kt  \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mRecomendada\u001b[0m\u001b[33m \u001b[0m \n",
              " \u001b[33m \u001b[0m\u001b[33mRICARDO BARBOSA  \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     29.0\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m2.56\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mModerada\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m   6\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     14.5%\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m$1.37M   \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m6.6kt  \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mRecomendada\u001b[0m\u001b[33m \u001b[0m \n",
              " \u001b[33m \u001b[0m\u001b[33mCARLA SILVA      \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     26.1\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m2.44\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mModerada\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m  41\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     13.5%\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m$1.28M   \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m6.2kt  \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mRecomendada\u001b[0m\u001b[33m \u001b[0m \n",
              " \u001b[33m \u001b[0m\u001b[33mPAULO MOURA      \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     22.5\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m 2.3\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mModerada\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m 105\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m     12.4%\u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m$1.18M   \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33m5.6kt  \u001b[0m\u001b[33m \u001b[0m \u001b[33m \u001b[0m\u001b[33mRecomendada\u001b[0m\u001b[33m \u001b[0m \n",
              " \u001b[34m \u001b[0m\u001b[34mRAFAEL SANTOS    \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m     10.7\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m1.69\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34mLeve    \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m  42\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m      8.5%\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m$0.80M   \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m3.8kt  \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34mMonitorar  \u001b[0m\u001b[34m \u001b[0m \n",
              " \u001b[34m \u001b[0m\u001b[34mHENRIQUE ALVES   \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m      9.9\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m1.64\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34mLeve    \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m  53\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m      8.2%\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m$0.78M   \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m3.7kt  \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34mMonitorar  \u001b[0m\u001b[34m \u001b[0m \n",
              " \u001b[34m \u001b[0m\u001b[34mROMARIO SILVA    \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m      6.7\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m1.41\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34mLeve    \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m   9\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m      7.0%\u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m$0.67M   \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34m3.2kt  \u001b[0m\u001b[34m \u001b[0m \u001b[34m \u001b[0m\u001b[34mMonitorar  \u001b[0m\u001b[34m \u001b[0m \n",
              "                                                                                                           \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                             Condi√ß√£o da Frota                                             </span>\n",
              "                                                                                                           \n",
              " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Navio             </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Incrust.% </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">  IMO </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Status   </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Dias </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Penalidade </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Custo/Ano </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> CO2/Ano </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> A√ß√£o        </span> \n",
              " ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> BRUNO LIMA        </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  565 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> DANIEL PEREIRA    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  771 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> VICTOR OLIVEIRA   </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  915 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> MARCOS CAVALCANTI </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  666 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> GABRIELA MARTINS  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      81.9 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  598 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      29.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $2.75M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 13.2kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> MARIA VALENTINA   </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      73.5 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  374 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      26.2% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $2.48M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 11.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> FELIPE RIBEIRO    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      72.3 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  478 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      25.8% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $2.44M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 11.7kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> RODRIGO PINHEIRO  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      70.8 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  460 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      25.3% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $2.40M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 11.5kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata    </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000\"> EDUARDO COSTA     </span> <span style=\"color: #800000; text-decoration-color: #800000\">      50.1 </span> <span style=\"color: #800000; text-decoration-color: #800000\"> 3.34 </span> <span style=\"color: #800000; text-decoration-color: #800000\"> Pesada   </span> <span style=\"color: #800000; text-decoration-color: #800000\">  181 </span> <span style=\"color: #800000; text-decoration-color: #800000\">      20.4% </span> <span style=\"color: #800000; text-decoration-color: #800000\"> $1.93M    </span> <span style=\"color: #800000; text-decoration-color: #800000\"> 9.3kt   </span> <span style=\"color: #800000; text-decoration-color: #800000\"> Urgente     </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000\"> GISELLE CARVALHO  </span> <span style=\"color: #800000; text-decoration-color: #800000\">      45.5 </span> <span style=\"color: #800000; text-decoration-color: #800000\"> 3.19 </span> <span style=\"color: #800000; text-decoration-color: #800000\"> Pesada   </span> <span style=\"color: #800000; text-decoration-color: #800000\">  247 </span> <span style=\"color: #800000; text-decoration-color: #800000\">      19.3% </span> <span style=\"color: #800000; text-decoration-color: #800000\"> $1.83M    </span> <span style=\"color: #800000; text-decoration-color: #800000\"> 8.8kt   </span> <span style=\"color: #800000; text-decoration-color: #800000\"> Urgente     </span> \n",
              " <span style=\"color: #808000; text-decoration-color: #808000\"> THIAGO FERNANDES  </span> <span style=\"color: #808000; text-decoration-color: #808000\">      34.7 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 2.79 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Moderada </span> <span style=\"color: #808000; text-decoration-color: #808000\">   42 </span> <span style=\"color: #808000; text-decoration-color: #808000\">      16.3% </span> <span style=\"color: #808000; text-decoration-color: #808000\"> $1.55M    </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 7.4kt   </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Recomendada </span> \n",
              " <span style=\"color: #808000; text-decoration-color: #808000\"> RAUL MARTINS      </span> <span style=\"color: #808000; text-decoration-color: #808000\">      32.0 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 2.68 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Moderada </span> <span style=\"color: #808000; text-decoration-color: #808000\">  148 </span> <span style=\"color: #808000; text-decoration-color: #808000\">      15.4% </span> <span style=\"color: #808000; text-decoration-color: #808000\"> $1.46M    </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 7.0kt   </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Recomendada </span> \n",
              " <span style=\"color: #808000; text-decoration-color: #808000\"> RICARDO BARBOSA   </span> <span style=\"color: #808000; text-decoration-color: #808000\">      29.0 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 2.56 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Moderada </span> <span style=\"color: #808000; text-decoration-color: #808000\">    6 </span> <span style=\"color: #808000; text-decoration-color: #808000\">      14.5% </span> <span style=\"color: #808000; text-decoration-color: #808000\"> $1.37M    </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 6.6kt   </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Recomendada </span> \n",
              " <span style=\"color: #808000; text-decoration-color: #808000\"> CARLA SILVA       </span> <span style=\"color: #808000; text-decoration-color: #808000\">      26.1 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 2.44 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Moderada </span> <span style=\"color: #808000; text-decoration-color: #808000\">   41 </span> <span style=\"color: #808000; text-decoration-color: #808000\">      13.5% </span> <span style=\"color: #808000; text-decoration-color: #808000\"> $1.28M    </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 6.2kt   </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Recomendada </span> \n",
              " <span style=\"color: #808000; text-decoration-color: #808000\"> PAULO MOURA       </span> <span style=\"color: #808000; text-decoration-color: #808000\">      22.5 </span> <span style=\"color: #808000; text-decoration-color: #808000\">  2.3 </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Moderada </span> <span style=\"color: #808000; text-decoration-color: #808000\">  105 </span> <span style=\"color: #808000; text-decoration-color: #808000\">      12.4% </span> <span style=\"color: #808000; text-decoration-color: #808000\"> $1.18M    </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 5.6kt   </span> <span style=\"color: #808000; text-decoration-color: #808000\"> Recomendada </span> \n",
              " <span style=\"color: #000080; text-decoration-color: #000080\"> RAFAEL SANTOS     </span> <span style=\"color: #000080; text-decoration-color: #000080\">      10.7 </span> <span style=\"color: #000080; text-decoration-color: #000080\"> 1.69 </span> <span style=\"color: #000080; text-decoration-color: #000080\"> Leve     </span> <span style=\"color: #000080; text-decoration-color: #000080\">   42 </span> <span style=\"color: #000080; text-decoration-color: #000080\">       8.5% </span> <span style=\"color: #000080; text-decoration-color: #000080\"> $0.80M    </span> <span style=\"color: #000080; text-decoration-color: #000080\"> 3.8kt   </span> <span style=\"color: #000080; text-decoration-color: #000080\"> Monitorar   </span> \n",
              " <span style=\"color: #000080; text-decoration-color: #000080\"> HENRIQUE ALVES    </span> <span style=\"color: #000080; text-decoration-color: #000080\">       9.9 </span> <span style=\"color: #000080; text-decoration-color: #000080\"> 1.64 </span> <span style=\"color: #000080; text-decoration-color: #000080\"> Leve     </span> <span style=\"color: #000080; text-decoration-color: #000080\">   53 </span> <span style=\"color: #000080; text-decoration-color: #000080\">       8.2% </span> <span style=\"color: #000080; text-decoration-color: #000080\"> $0.78M    </span> <span style=\"color: #000080; text-decoration-color: #000080\"> 3.7kt   </span> <span style=\"color: #000080; text-decoration-color: #000080\"> Monitorar   </span> \n",
              " <span style=\"color: #000080; text-decoration-color: #000080\"> ROMARIO SILVA     </span> <span style=\"color: #000080; text-decoration-color: #000080\">       6.7 </span> <span style=\"color: #000080; text-decoration-color: #000080\"> 1.41 </span> <span style=\"color: #000080; text-decoration-color: #000080\"> Leve     </span> <span style=\"color: #000080; text-decoration-color: #000080\">    9 </span> <span style=\"color: #000080; text-decoration-color: #000080\">       7.0% </span> <span style=\"color: #000080; text-decoration-color: #000080\"> $0.67M    </span> <span style=\"color: #000080; text-decoration-color: #000080\"> 3.2kt   </span> <span style=\"color: #000080; text-decoration-color: #000080\"> Monitorar   </span> \n",
              "                                                                                                           \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36mESTAT√çSTICAS DA FROTA\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ESTAT√çSTICAS DA FROTA</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \n",
              "Distribui√ß√£o:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  \n",
              "Distribui√ß√£o:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Limpo \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m%\u001b[1m)\u001b[0m:      \u001b[1;36m0\u001b[0m navios \u001b[1m(\u001b[0m  \u001b[1;36m0.0\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Limpo <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>%<span style=\"font-weight: bold\">)</span>:      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> navios <span style=\"font-weight: bold\">(</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Leve \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m-\u001b[1;36m15\u001b[0m%\u001b[1m)\u001b[0m:      \u001b[1;36m3\u001b[0m navios \u001b[1m(\u001b[0m \u001b[1;36m16.7\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Leve <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>%<span style=\"font-weight: bold\">)</span>:      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> navios <span style=\"font-weight: bold\">(</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.7</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Moderada \u001b[1m(\u001b[0m\u001b[1;36m15\u001b[0m-\u001b[1;36m40\u001b[0m%\u001b[1m)\u001b[0m:  \u001b[1;36m5\u001b[0m navios \u001b[1m(\u001b[0m \u001b[1;36m27.8\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Moderada <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>%<span style=\"font-weight: bold\">)</span>:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> navios <span style=\"font-weight: bold\">(</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27.8</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Pesada \u001b[1m(\u001b[0m\u001b[1;36m40\u001b[0m-\u001b[1;36m70\u001b[0m%\u001b[1m)\u001b[0m:    \u001b[1;36m2\u001b[0m navios \u001b[1m(\u001b[0m \u001b[1;36m11.1\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Pesada <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>%<span style=\"font-weight: bold\">)</span>:    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> navios <span style=\"font-weight: bold\">(</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.1</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Cr√≠tica \u001b[1m(\u001b[0m\u001b[1;36m70\u001b[0m-\u001b[1;36m100\u001b[0m%\u001b[1m)\u001b[0m:  \u001b[1;36m8\u001b[0m navios \u001b[1m(\u001b[0m \u001b[1;36m44.4\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Cr√≠tica <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>%<span style=\"font-weight: bold\">)</span>:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> navios <span style=\"font-weight: bold\">(</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44.4</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \n",
              "A√ß√µes Requeridas:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  \n",
              "A√ß√µes Requeridas:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[33m‚ö†\u001b[0m \u001b[1;36m10\u001b[0m navios requerem limpeza urgente \u001b[1m(\u001b[0m‚â•\u001b[1;36m40\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">‚ö†</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> navios requerem limpeza urgente <span style=\"font-weight: bold\">(</span>‚â•<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    \u001b[1;36m5\u001b[0m navios requerem limpeza recomendada \u001b[1m(\u001b[0m\u001b[1;36m15\u001b[0m-\u001b[1;36m40\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> navios requerem limpeza recomendada <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    \u001b[1;36m3\u001b[0m navios requerem monitoramento \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m-\u001b[1;36m15\u001b[0m%\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> navios requerem monitoramento <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>%<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \n",
              "Impacto Econ√¥mico Total:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  \n",
              "Impacto Econ√¥mico Total:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Custo Extra/Ano: $\u001b[1;36m36.\u001b[0m20M | M√©dio/Navio: $\u001b[1;36m2.\u001b[0m01M\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Custo Extra/Ano: $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36.</span>20M | M√©dio/Navio: $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.</span>01M\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    CO2 Extra/Ano: \u001b[1;36m173.\u001b[0m5kt | M√©dio/Navio: \u001b[1;36m9.\u001b[0m6kt\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    CO2 Extra/Ano: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">173.</span>5kt | M√©dio/Navio: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>6kt\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m Resultados salvos em: fouling_por_navio.csv\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span> Resultados salvos em: fouling_por_navio.csv\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14. VALIDA√á√ÉO COM NAVIOS DE TESTE"
      ],
      "metadata": {
        "id": "PGm46P9UGzpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_header(\"VALIDA√á√ÉO COM NAVIOS DE TESTE\")\n",
        "\n",
        "# Verificar se existem dados de valida√ß√£o\n",
        "VALIDATION_PATH = \"Hackathon Transpetro/Mais Dados/\"\n",
        "\n",
        "\n",
        "if os.path.exists(VALIDATION_PATH):\n",
        "\n",
        "    try:\n",
        "        # Carregar dados de valida√ß√£o com fallback para arquivos principais\n",
        "        print_info(\"Carregando dados de valida√ß√£o...\")\n",
        "\n",
        "        # Tentar carregar eventos de valida√ß√£o, sen√£o usar principal\n",
        "        try:\n",
        "            df_eventos_val = pd.read_csv(f\"{VALIDATION_PATH}Eventos_Validacao 1.CSV\")\n",
        "        except FileNotFoundError:\n",
        "            df_eventos_val = df_eventos.copy()\n",
        "\n",
        "        # Tentar carregar consumo de valida√ß√£o, sen√£o usar principal\n",
        "        try:\n",
        "            df_consumo_val = pd.read_csv(f\"{VALIDATION_PATH}Consumo_Validacao 1.CSV\")\n",
        "            print_success(f\"  Consumo de valida√ß√£o: {df_consumo_val.shape[0]} registros\")\n",
        "        except FileNotFoundError:\n",
        "            print_warning(\"  Consumo_Validacao n√£o encontrado, usando ResultadoQueryConsumo.csv\")\n",
        "            df_consumo_val = df_consumo.copy()\n",
        "\n",
        "        # Tentar carregar dados navios de valida√ß√£o, sen√£o usar principal\n",
        "        try:\n",
        "            df_navios_val = pd.read_excel(f\"{VALIDATION_PATH}Dados navios Valida√ß√£o 1.xlsx\")\n",
        "            print_success(f\"  Dados navios de valida√ß√£o: {df_navios_val.shape[0]} registros\")\n",
        "        except FileNotFoundError:\n",
        "            print_warning(\"  Dados navios Valida√ß√£o n√£o encontrado, usando Dados navios Hackathon.xlsx\")\n",
        "            df_navios_val = df_navios.copy()\n",
        "\n",
        "        # Carregar AIS dos navios teste com fallback\n",
        "        df_ais_val = pd.DataFrame()\n",
        "\n",
        "        # Tentar carregar AIS TESTE 2\n",
        "        try:\n",
        "            df_ais_teste2 = pd.read_csv(f\"{VALIDATION_PATH}AIS_NAVIO TESTE 2 1.csv\")\n",
        "            df_ais_val = pd.concat([df_ais_val, df_ais_teste2], ignore_index=True)\n",
        "            print_success(f\"  AIS TESTE 2: {df_ais_teste2.shape[0]} registros\")\n",
        "        except FileNotFoundError:\n",
        "            print_warning(\"  AIS_NAVIO TESTE 2 n√£o encontrado\")\n",
        "\n",
        "        # Tentar carregar AIS TESTE 3\n",
        "        try:\n",
        "            df_ais_teste3 = pd.read_csv(f\"{VALIDATION_PATH}AIS_NAVIO TESTE 3 1.csv\")\n",
        "            df_ais_val = pd.concat([df_ais_val, df_ais_teste3], ignore_index=True)\n",
        "            print_success(f\"  AIS TESTE 3: {df_ais_teste3.shape[0]} registros\")\n",
        "        except FileNotFoundError:\n",
        "            print_warning(\"  AIS_NAVIO TESTE 3 n√£o encontrado\")\n",
        "\n",
        "\n",
        "\n",
        "        # Template de resultado\n",
        "        try:\n",
        "            df_resultado = pd.read_excel(f\"{VALIDATION_PATH}RESULTADO Valida√ß√£o 1.xlsx\", header=0)\n",
        "\n",
        "            # Renomear colunas corretamente\n",
        "            if 'Unnamed: 0' in df_resultado.columns:\n",
        "                df_resultado.columns = ['Embarca√ß√£o', 'Data', 'Condi√ß√£o do Casco']\n",
        "\n",
        "            # Remover primeira linha se for cabe√ßalho duplicado\n",
        "            if len(df_resultado) > 0 and str(df_resultado.iloc[0]['Embarca√ß√£o']).strip().upper() == 'EMBARCA√á√ÉO':\n",
        "                df_resultado = df_resultado.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "            # Remover linhas vazias e inv√°lidas\n",
        "            df_resultado = df_resultado.dropna(subset=['Embarca√ß√£o', 'Data'], how='any')\n",
        "            df_resultado = df_resultado[df_resultado['Embarca√ß√£o'].str.strip() != '']\n",
        "            df_resultado = df_resultado[~df_resultado['Embarca√ß√£o'].str.contains('teste 1', case=False, na=False)]\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print_warning(\"  RESULTADO Valida√ß√£o n√£o encontrado, criando template com todos os navios\")\n",
        "            # Criar template com todos os navios √∫nicos dos eventos\n",
        "            navios_unicos = df_eventos_val['shipName'].unique()\n",
        "            datas_recentes = df_eventos_val.groupby('shipName')['startGMTDate'].max().reset_index()\n",
        "            df_resultado = pd.DataFrame({\n",
        "                'Embarca√ß√£o': datas_recentes['shipName'],\n",
        "                'Data': datas_recentes['startGMTDate'],\n",
        "                'Condi√ß√£o do Casco': ''\n",
        "            })\n",
        "\n",
        "        print_success(f\"\\nResumo dos dados de valida√ß√£o:\")\n",
        "        print_info(f\"  Eventos: {df_eventos_val.shape[0]} | AIS: {df_ais_val.shape[0]} | Template: {df_resultado.shape[0]}\")\n",
        "\n",
        "        # Pr√©-processar dados de valida√ß√£o\n",
        "        df_eventos_val.columns = df_eventos_val.columns.str.strip()\n",
        "        df_consumo_val.columns = df_consumo_val.columns.str.strip()\n",
        "        df_ais_val.columns = df_ais_val.columns.str.strip()\n",
        "\n",
        "        # Parse datetimes\n",
        "        for c in [\"startGMTDate\", \"endGMTDate\"]:\n",
        "            if c in df_eventos_val.columns:\n",
        "                df_eventos_val[c] = pd.to_datetime(df_eventos_val[c], format='%d/%m/%Y %H:%M', errors='coerce')\n",
        "\n",
        "        # Renomear SESSION_ID\n",
        "        if \"SESSION_ID\" in df_consumo_val.columns:\n",
        "            df_consumo_val.rename(columns={\"SESSION_ID\": \"sessionId\"}, inplace=True)\n",
        "\n",
        "        # Processar AIS\n",
        "        if 'DATAHORA' in df_ais_val.columns:\n",
        "            df_ais_val['DATETIME'] = pd.to_datetime(df_ais_val['DATAHORA'], errors='coerce')\n",
        "\n",
        "        if 'VELOCIDADE' in df_ais_val.columns:\n",
        "            df_ais_val['speed_kn'] = pd.to_numeric(df_ais_val['VELOCIDADE'], errors='coerce')\n",
        "\n",
        "        if 'NOME' in df_ais_val.columns:\n",
        "            df_ais_val['shipName_ais'] = df_ais_val['NOME'].astype(str)\n",
        "\n",
        "        # Identificar quais navios do template precisamos processar\n",
        "        navios_no_template = df_resultado['Embarca√ß√£o'].str.upper().unique()\n",
        "\n",
        "        # Agregar AIS por evento - COMBINAR eventos de valida√ß√£o E principais\n",
        "        print_info(\"Processando eventos de valida√ß√£o...\")\n",
        "        df_events_ais_val_only = aggregate_ais_by_event(df_eventos_val, df_ais_val)\n",
        "\n",
        "        # Verificar quais navios do template N√ÉO est√£o nos eventos de valida√ß√£o\n",
        "        if not df_events_ais_val_only.empty:\n",
        "            navios_em_validacao = set(df_events_ais_val_only['shipName'].str.upper().unique())\n",
        "        else:\n",
        "            navios_em_validacao = set()\n",
        "\n",
        "        navios_faltantes = set(navios_no_template) - navios_em_validacao\n",
        "\n",
        "        if navios_faltantes:\n",
        "\n",
        "            # Filtrar eventos principais para incluir APENAS os navios que faltam\n",
        "            df_eventos_faltantes = df_eventos[df_eventos['shipName'].str.upper().isin(navios_faltantes)].copy()\n",
        "\n",
        "            if not df_eventos_faltantes.empty:\n",
        "                df_events_ais_main_filtered = aggregate_ais_by_event(df_eventos_faltantes, df_ais)\n",
        "            else:\n",
        "                df_events_ais_main_filtered = pd.DataFrame()\n",
        "        else:\n",
        "            df_events_ais_main_filtered = pd.DataFrame()\n",
        "\n",
        "        # Combinar eventos de valida√ß√£o + principais (apenas navios faltantes)\n",
        "        if not df_events_ais_val_only.empty and not df_events_ais_main_filtered.empty:\n",
        "            df_events_ais_val = pd.concat([df_events_ais_val_only, df_events_ais_main_filtered], ignore_index=True)\n",
        "        elif not df_events_ais_val_only.empty:\n",
        "            df_events_ais_val = df_events_ais_val_only\n",
        "        elif not df_events_ais_main_filtered.empty:\n",
        "            df_events_ais_val = df_events_ais_main_filtered\n",
        "        else:\n",
        "            df_events_ais_val = pd.DataFrame()\n",
        "\n",
        "\n",
        "        if not df_events_ais_val.empty:\n",
        "            # Criar features avan√ßadas\n",
        "            df_events_ais_val = create_advanced_features(df_events_ais_val)\n",
        "\n",
        "            # Processar IWS e DOCAGEM para calcular dias desde limpeza CORRETAMENTE\n",
        "            # Combinar eventos de valida√ß√£o + principais para buscar todas as docagens\n",
        "            print_info(\"Calculando dias desde √∫ltima limpeza (IWS + DOCAGEM)...\")\n",
        "\n",
        "            # Combinar eventos de valida√ß√£o e principais para ter todas as docagens\n",
        "            df_eventos_combinados = pd.concat([df_eventos_val, df_eventos], ignore_index=True)\n",
        "\n",
        "            # Processar com eventos combinados\n",
        "            df_events_ais_val = process_iws_and_docking_data(df_iws, df_eventos_combinados, df_events_ais_val)\n",
        "\n",
        "            # Criar est√°gio de fouling baseado em days_since_clean\n",
        "            def get_stage(days):\n",
        "                if pd.isna(days):\n",
        "                    return 2\n",
        "                if days < 14:\n",
        "                    return 0\n",
        "                elif days < 42:\n",
        "                    return 1\n",
        "                elif days < 90:\n",
        "                    return 2\n",
        "                else:\n",
        "                    return 3\n",
        "\n",
        "            # Garantir que fouling_stage existe\n",
        "            if 'fouling_stage' not in df_events_ais_val.columns:\n",
        "                df_events_ais_val['fouling_stage'] = df_events_ais_val['days_since_clean'].apply(get_stage)\n",
        "\n",
        "            # Criar biofouling risk score\n",
        "            df_events_ais_val['biofouling_risk_score'] = (\n",
        "                0.4 * (df_events_ais_val['days_since_clean'].fillna(90) / 180).clip(0, 1) +\n",
        "                0.25 * (df_events_ais_val['velocity_risk'] / 3) +\n",
        "                0.2 * df_events_ais_val['idle_time_ratio'] +\n",
        "                0.15 * df_events_ais_val['temp_risk']\n",
        "            ).clip(0, 1)\n",
        "\n",
        "            # Merge com consumo\n",
        "            if 'sessionId' in df_consumo_val.columns:\n",
        "                df_cons_sum = df_consumo_val.groupby('sessionId', as_index=False)['CONSUMED_QUANTITY'].sum()\n",
        "                df_events_ais_val = df_events_ais_val.merge(df_cons_sum, on='sessionId', how='left')\n",
        "\n",
        "            # Preparar features para predi√ß√£o\n",
        "            features_missing = [f for f in features_available if f not in df_events_ais_val.columns]\n",
        "            for feat in features_missing:\n",
        "                df_events_ais_val[feat] = 0\n",
        "\n",
        "            df_pred_val = df_events_ais_val[features_available + ['shipName', 'startGMTDate']].copy()\n",
        "            df_pred_val[features_available] = df_pred_val[features_available].fillna(0)\n",
        "\n",
        "            X_val = df_pred_val[features_available].values\n",
        "\n",
        "\n",
        "            # Fazer predi√ß√µes com ensemble\n",
        "            predictions_val = {}\n",
        "            for name, model in models.items():\n",
        "                pred = model.predict(X_val)\n",
        "                predictions_val[name] = pred\n",
        "\n",
        "            # Ensemble com pesos\n",
        "            y_pred_val_ensemble = sum(predictions_val[name] * weight for name, weight in zip(models.keys(), weights))\n",
        "\n",
        "            df_pred_val['fouling_percentage'] = y_pred_val_ensemble\n",
        "\n",
        "            # Converter para IMO\n",
        "            def percentage_to_imo_rating(pct):\n",
        "                if pd.isna(pct):\n",
        "                    return np.nan\n",
        "                if pct < 0.5:\n",
        "                    return 0.0\n",
        "                elif pct < 1.0:\n",
        "                    return 0.5 + (pct - 0.5)\n",
        "                elif pct < 15.0:\n",
        "                    return 1.0 + (pct - 1.0) / 14.0\n",
        "                elif pct < 40.0:\n",
        "                    return 2.0 + (pct - 15.0) / 25.0\n",
        "                elif pct < 70.0:\n",
        "                    return 3.0 + (pct - 40.0) / 30.0\n",
        "                else:\n",
        "                    return 4.0\n",
        "\n",
        "            df_pred_val['fouling_rating_imo'] = df_pred_val['fouling_percentage'].apply(percentage_to_imo_rating)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Converter datas (podem j√° estar como datetime ou string)\n",
        "            if 'Data' in df_resultado.columns:\n",
        "                df_resultado['Data'] = pd.to_datetime(df_resultado['Data'], errors='coerce')\n",
        "\n",
        "\n",
        "            resultados_preenchidos = []\n",
        "            navios_sem_dados = []\n",
        "\n",
        "            for idx, row in df_resultado.iterrows():\n",
        "                navio = str(row.get('Embarca√ß√£o', row.get('Navio', ''))).strip()\n",
        "                data_alvo = row.get('Data')\n",
        "\n",
        "                # Verificar se temos dados v√°lidos\n",
        "                if pd.isna(data_alvo) or navio == '' or navio == 'nan':\n",
        "                    navios_sem_dados.append(navio)\n",
        "                    continue\n",
        "\n",
        "                # Buscar predi√ß√µes para este navio (busca mais robusta)\n",
        "                # Tentar match exato primeiro\n",
        "                mask = df_pred_val['shipName'].str.upper() == navio.upper()\n",
        "                if not mask.any():\n",
        "                    # Tentar match parcial\n",
        "                    mask = df_pred_val['shipName'].str.upper().str.contains(navio.upper(), na=False)\n",
        "\n",
        "                preds_navio = df_pred_val[mask].copy()\n",
        "\n",
        "                if preds_navio.empty:\n",
        "                    # N√£o incluir navios sem predi√ß√µes\n",
        "                    navios_sem_dados.append(navio)\n",
        "                    continue\n",
        "\n",
        "                # Encontrar predi√ß√µes antes e depois da data alvo\n",
        "                preds_antes = preds_navio[preds_navio['startGMTDate'] <= data_alvo]\n",
        "                preds_depois = preds_navio[preds_navio['startGMTDate'] > data_alvo]\n",
        "\n",
        "                if not preds_antes.empty and not preds_depois.empty:\n",
        "                    # Interpolar entre antes e depois\n",
        "                    pred_antes = preds_antes.iloc[-1]  # √öltima antes\n",
        "                    pred_depois = preds_depois.iloc[0]  # Primeira depois\n",
        "\n",
        "                    # Interpola√ß√£o linear\n",
        "                    dias_antes = (data_alvo - pred_antes['startGMTDate']).days\n",
        "                    dias_depois = (pred_depois['startGMTDate'] - data_alvo).days\n",
        "                    total_dias = dias_antes + dias_depois\n",
        "\n",
        "                    if total_dias > 0:\n",
        "                        peso_antes = dias_depois / total_dias\n",
        "                        peso_depois = dias_antes / total_dias\n",
        "                        pct = pred_antes['fouling_percentage'] * peso_antes + pred_depois['fouling_percentage'] * peso_depois\n",
        "                        imo = pred_antes['fouling_rating_imo'] * peso_antes + pred_depois['fouling_rating_imo'] * peso_depois\n",
        "                    else:\n",
        "                        pct = pred_antes['fouling_percentage']\n",
        "                        imo = pred_antes['fouling_rating_imo']\n",
        "\n",
        "                elif not preds_antes.empty:\n",
        "                    # Usar √∫ltima predi√ß√£o antes da data\n",
        "                    closest = preds_antes.iloc[-1]\n",
        "                    pct = closest['fouling_percentage']\n",
        "                    imo = closest['fouling_rating_imo']\n",
        "\n",
        "                elif not preds_depois.empty:\n",
        "                    # Usar primeira predi√ß√£o depois da data\n",
        "                    closest = preds_depois.iloc[0]\n",
        "                    pct = closest['fouling_percentage']\n",
        "                    imo = closest['fouling_rating_imo']\n",
        "\n",
        "                else:\n",
        "                    # Fallback: predi√ß√£o mais pr√≥xima\n",
        "                    preds_navio['time_diff'] = (preds_navio['startGMTDate'] - data_alvo).abs()\n",
        "                    closest = preds_navio.loc[preds_navio['time_diff'].idxmin()]\n",
        "                    pct = closest['fouling_percentage']\n",
        "                    imo = closest['fouling_rating_imo']\n",
        "\n",
        "                # Classificar\n",
        "                if pct < 1.0:\n",
        "                    classe = \"Limpo/Micro\"\n",
        "                elif pct < 15.0:\n",
        "                    classe = \"Leve\"\n",
        "                elif pct < 40.0:\n",
        "                    classe = \"Moderada\"\n",
        "                elif pct < 70.0:\n",
        "                    classe = \"Pesada\"\n",
        "                else:\n",
        "                    classe = \"Cr√≠tica\"\n",
        "\n",
        "                condicao = f\"{pct:.1f}% ({classe}, IMO {imo:.2f})\"\n",
        "\n",
        "                # Formatar data corretamente para Excel\n",
        "                data_formatada = data_alvo.strftime('%d/%m/%Y') if pd.notna(data_alvo) else ''\n",
        "\n",
        "                resultados_preenchidos.append({\n",
        "                    'Embarca√ß√£o': navio,\n",
        "                    'Data': data_formatada,\n",
        "                    'Condi√ß√£o do Casco': condicao\n",
        "                })\n",
        "\n",
        "            # Informar sobre navios exclu√≠dos (apenas se houver)\n",
        "            navios_validos = [n for n in navios_sem_dados if n and n != 'nan' and 'teste 1' not in n.lower()]\n",
        "            df_resultado_final = pd.DataFrame(resultados_preenchidos)\n",
        "\n",
        "            # Salvar resultado\n",
        "            output_file = 'RESULTADO_Validacao_Preenchido.xlsx'\n",
        "            df_resultado_final.to_excel(output_file, index=False)\n",
        "\n",
        "            print_success(f\"Resultado salvo em: {output_file}\")\n",
        "\n",
        "            # Relat√≥rio detalhado por navio (similar √† frota principal)\n",
        "            print_header(\"RELAT√ìRIO DE VALIDA√á√ÉO\")\n",
        "\n",
        "\n",
        "            # Criar relat√≥rio baseado nas DATAS DE AVALIA√á√ÉO do template\n",
        "            # Cada linha do template = uma predi√ß√£o separada\n",
        "            resultados_validacao = []\n",
        "\n",
        "            # Usar os resultados j√° preenchidos (que t√™m as predi√ß√µes para cada data)\n",
        "            for resultado in resultados_preenchidos:\n",
        "                navio = resultado['Embarca√ß√£o']\n",
        "                data_str = resultado['Data']\n",
        "                condicao = resultado['Condi√ß√£o do Casco']\n",
        "\n",
        "                # Extrair porcentagem e IMO da string de condi√ß√£o\n",
        "                # Formato: \"71.6% (Cr√≠tica, IMO 4.00)\"\n",
        "                if '%' in condicao and 'IMO' in condicao:\n",
        "                    try:\n",
        "                        pct_str = condicao.split('%')[0]\n",
        "                        fouling_pct = float(pct_str)\n",
        "\n",
        "                        imo_str = condicao.split('IMO ')[1].split(')')[0]\n",
        "                        fouling_imo = float(imo_str)\n",
        "\n",
        "                        classe = condicao.split('(')[1].split(',')[0]\n",
        "\n",
        "                        # Calcular impacto\n",
        "                        baseline = 40\n",
        "                        impacto = compute_fuel_penalty_from_fouling(fouling_pct, baseline)\n",
        "\n",
        "                        # Determinar a√ß√£o\n",
        "                        if fouling_pct < 1.0:\n",
        "                            acao = \"OK\"\n",
        "                        elif fouling_pct < 15.0:\n",
        "                            acao = \"Monitorar\"\n",
        "                        elif fouling_pct < 40.0:\n",
        "                            acao = \"Recomendada\"\n",
        "                        elif fouling_pct < 70.0:\n",
        "                            acao = \"Urgente\"\n",
        "                        else:\n",
        "                            acao = \"Imediata\"\n",
        "\n",
        "                        # Buscar dias desde limpeza para esta data espec√≠fica\n",
        "                        # Converter data string de volta para datetime para buscar\n",
        "                        data_dt = pd.to_datetime(data_str, format='%d/%m/%Y')\n",
        "\n",
        "                        # Buscar predi√ß√µes pr√≥ximas a esta data\n",
        "                        mask = df_pred_val['shipName'].str.upper() == navio.upper()\n",
        "                        preds_navio = df_pred_val[mask]\n",
        "\n",
        "                        if not preds_navio.empty:\n",
        "                            # Encontrar predi√ß√£o mais pr√≥xima desta data\n",
        "                            preds_navio_copy = preds_navio.copy()\n",
        "                            preds_navio_copy['time_diff'] = (preds_navio_copy['startGMTDate'] - data_dt).abs()\n",
        "                            closest_pred = preds_navio_copy.loc[preds_navio_copy['time_diff'].idxmin()]\n",
        "                            days_clean = closest_pred.get('days_since_clean', np.nan)\n",
        "                        else:\n",
        "                            days_clean = np.nan\n",
        "\n",
        "                        resultados_validacao.append({\n",
        "                            'Navio': navio,\n",
        "                            'Data': data_str,\n",
        "                            'Incrust.%': round(fouling_pct, 1),\n",
        "                            'IMO': round(fouling_imo, 2),\n",
        "                            'Status': classe,\n",
        "                            'Dias*': f\"{int(days_clean)}*\" if not pd.isna(days_clean) else 'N/A',\n",
        "                            'Penalidade': f\"{impacto['fuel_penalty_pct']:.1f}%\",\n",
        "                            'Custo/Ano': f\"${impacto['extra_cost_usd_year']/1e6:.2f}M\",\n",
        "                            'CO2/Ano': f\"{impacto['extra_co2_tons_year']/1e3:.1f}kt\",\n",
        "                            'A√ß√£o': acao\n",
        "                        })\n",
        "                    except Exception as e:\n",
        "                        print_warning(f\"Erro ao processar resultado para {navio}: {e}\")\n",
        "\n",
        "            df_validacao = pd.DataFrame(resultados_validacao)\n",
        "            df_validacao = df_validacao.sort_values('Incrust.%', ascending=False)\n",
        "\n",
        "            # Imprimir tabela\n",
        "            if RICH_AVAILABLE:\n",
        "                table = Table(title=\"Navios de Valida√ß√£o\", box=box.SIMPLE_HEAD, show_header=True, header_style=\"bold cyan\")\n",
        "\n",
        "                for col in df_validacao.columns:\n",
        "                    justify = \"right\" if col in ['Incrust.%', 'IMO', 'Dias*', 'Eventos', 'Penalidade'] else \"left\"\n",
        "                    table.add_column(col, justify=justify)\n",
        "\n",
        "                for _, row in df_validacao.iterrows():\n",
        "                    status = row['Status']\n",
        "                    if status == 'Cr√≠tica':\n",
        "                        style = \"bold red\"\n",
        "                    elif status == 'Pesada':\n",
        "                        style = \"red\"\n",
        "                    elif status == 'Moderada':\n",
        "                        style = \"yellow\"\n",
        "                    elif status == 'Leve':\n",
        "                        style = \"blue\"\n",
        "                    else:\n",
        "                        style = \"green\"\n",
        "\n",
        "                    table.add_row(*[str(val) for val in row], style=style)\n",
        "\n",
        "                console.print(table)\n",
        "            else:\n",
        "                print(\"\\n\" + df_validacao.to_string(index=False))\n",
        "\n",
        "            # Estat√≠sticas de valida√ß√£o (por avalia√ß√£o)\n",
        "            incrust_values = df_validacao['Incrust.%'].values\n",
        "\n",
        "            # Distribui√ß√£o\n",
        "            clean_count = (incrust_values < 1.0).sum()\n",
        "            leve_count = ((incrust_values >= 1.0) & (incrust_values < 15.0)).sum()\n",
        "            moderada_count = ((incrust_values >= 15.0) & (incrust_values < 40.0)).sum()\n",
        "            pesada_count = ((incrust_values >= 40.0) & (incrust_values < 70.0)).sum()\n",
        "            critica_count = (incrust_values >= 70.0).sum()\n",
        "            total_val = len(incrust_values)\n",
        "\n",
        "\n",
        "\n",
        "            # Contar avalia√ß√µes cr√≠ticas e urgentes\n",
        "            aval_criticas = (incrust_values >= 70).sum()\n",
        "            aval_urgentes = (incrust_values >= 40).sum()\n",
        "            total_aval = len(incrust_values)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Salvar predi√ß√µes detalhadas\n",
        "            df_pred_export = df_pred_val[['shipName', 'startGMTDate', 'fouling_percentage',\n",
        "                                          'fouling_rating_imo']].copy()\n",
        "            df_pred_export.to_csv('predicoes_validacao_detalhadas.csv', index=False)\n",
        "            print_success(\"Predi√ß√µes detalhadas salvas em: predicoes_validacao_detalhadas.csv\")\n",
        "\n",
        "            print_success(f\"\\nValida√ß√£o conclu√≠da! Arquivos gerados:\")\n",
        "            print_info(f\"  1. {output_file}\")\n",
        "            print_info(f\"  2. predicoes_validacao_detalhadas.csv\")\n",
        "\n",
        "        else:\n",
        "            print_warning(\"Nenhum evento com dados AIS encontrado para valida√ß√£o\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print_warning(f\"Alguns arquivos de valida√ß√£o n√£o foram encontrados: {e}\")\n",
        "        print_info(\"  Valida√ß√£o ser√° pulada\")\n",
        "    except Exception as e:\n",
        "        print_warning(f\"Erro durante valida√ß√£o: {e}\")\n",
        "        print_info(\"  Valida√ß√£o ser√° pulada\")\n",
        "\n",
        "else:\n",
        "    print_warning(f\"Pasta de valida√ß√£o n√£o encontrada: {VALIDATION_PATH}\")\n",
        "    print_info(\"  Executando valida√ß√£o com dados principais...\")\n",
        "\n",
        "    try:\n",
        "        # Usar dados principais para valida√ß√£o\n",
        "        df_eventos_val = df_eventos.copy()\n",
        "        df_consumo_val = df_consumo.copy()\n",
        "        df_navios_val = df_navios.copy()\n",
        "        df_ais_val = df_ais.copy()\n",
        "\n",
        "        print_success(f\"Dados principais carregados para valida√ß√£o:\")\n",
        "        print_info(f\"  Eventos: {df_eventos_val.shape[0]} | AIS: {df_ais_val.shape[0]}\")\n",
        "\n",
        "        # Criar template com todos os navios\n",
        "        navios_unicos = df_eventos_val['shipName'].unique()\n",
        "        datas_recentes = df_eventos_val.groupby('shipName')['startGMTDate'].max().reset_index()\n",
        "        df_resultado = pd.DataFrame({\n",
        "            'Embarca√ß√£o': datas_recentes['shipName'],\n",
        "            'Data': datas_recentes['startGMTDate'],\n",
        "            'Condi√ß√£o do Casco': ''\n",
        "        })\n",
        "\n",
        "        # Processar valida√ß√£o com dados principais\n",
        "        # [O mesmo c√≥digo de processamento ser√° executado]\n",
        "\n",
        "        # Pr√©-processar dados de valida√ß√£o\n",
        "        df_eventos_val.columns = df_eventos_val.columns.str.strip()\n",
        "        df_consumo_val.columns = df_consumo_val.columns.str.strip()\n",
        "        df_ais_val.columns = df_ais_val.columns.str.strip()\n",
        "\n",
        "        # Parse datetimes\n",
        "        for c in [\"startGMTDate\", \"endGMTDate\"]:\n",
        "            if c in df_eventos_val.columns:\n",
        "                df_eventos_val[c] = pd.to_datetime(df_eventos_val[c], errors='coerce')\n",
        "\n",
        "        # Renomear SESSION_ID\n",
        "        if \"SESSION_ID\" in df_consumo_val.columns:\n",
        "            df_consumo_val.rename(columns={\"SESSION_ID\": \"sessionId\"}, inplace=True)\n",
        "\n",
        "        # Processar AIS\n",
        "        if 'DATAHORA' in df_ais_val.columns:\n",
        "            df_ais_val['DATETIME'] = pd.to_datetime(df_ais_val['DATAHORA'], errors='coerce')\n",
        "        elif 'DataHora' in df_ais_val.columns:\n",
        "            df_ais_val['DATETIME'] = pd.to_datetime(df_ais_val['DataHora'], errors='coerce')\n",
        "\n",
        "        if 'VELOCIDADE' in df_ais_val.columns:\n",
        "            df_ais_val['speed_kn'] = pd.to_numeric(df_ais_val['VELOCIDADE'], errors='coerce')\n",
        "        elif 'speed' in df_ais_val.columns:\n",
        "            df_ais_val['speed_kn'] = pd.to_numeric(df_ais_val['speed'], errors='coerce')\n",
        "\n",
        "        if 'NOME' in df_ais_val.columns:\n",
        "            df_ais_val['shipName_ais'] = df_ais_val['NOME'].astype(str)\n",
        "        elif 'shipName' in df_ais_val.columns:\n",
        "            df_ais_val['shipName_ais'] = df_ais_val['shipName'].astype(str)\n",
        "        elif 'ARQUIVO_ORIGEM' in df_ais_val.columns:\n",
        "            df_ais_val['shipName_ais'] = df_ais_val['ARQUIVO_ORIGEM'].str.replace('.csv', '').astype(str)\n",
        "\n",
        "        # Agregar AIS por evento\n",
        "        print_info(\"Processando eventos com dados principais...\")\n",
        "        df_events_ais_val = aggregate_ais_by_event(df_eventos_val, df_ais_val)\n",
        "\n",
        "        if not df_events_ais_val.empty:\n",
        "            # Criar features avan√ßadas\n",
        "            df_events_ais_val = create_advanced_features(df_events_ais_val)\n",
        "\n",
        "            # Processar IWS e criar days_since_clean\n",
        "            df_events_ais_val = process_iws_and_docking_data(df_iws, df_eventos_val, df_events_ais_val)\n",
        "\n",
        "            # Criar est√°gio de fouling\n",
        "            def get_stage(days):\n",
        "                if pd.isna(days):\n",
        "                    return 2\n",
        "                if days < 14:\n",
        "                    return 0\n",
        "                elif days < 42:\n",
        "                    return 1\n",
        "                elif days < 90:\n",
        "                    return 2\n",
        "                else:\n",
        "                    return 3\n",
        "\n",
        "            df_events_ais_val['fouling_stage'] = df_events_ais_val['days_since_clean'].apply(get_stage)\n",
        "\n",
        "            # Criar biofouling risk score\n",
        "            df_events_ais_val['biofouling_risk_score'] = (\n",
        "                0.4 * (df_events_ais_val['days_since_clean'].fillna(90) / 180).clip(0, 1) +\n",
        "                0.25 * (df_events_ais_val['velocity_risk'] / 3) +\n",
        "                0.2 * df_events_ais_val['idle_time_ratio'] +\n",
        "                0.15 * df_events_ais_val['temp_risk']\n",
        "            ).clip(0, 1)\n",
        "\n",
        "            # Merge com consumo\n",
        "            if 'sessionId' in df_consumo_val.columns:\n",
        "                df_cons_sum = df_consumo_val.groupby('sessionId', as_index=False)['CONSUMED_QUANTITY'].sum()\n",
        "                df_events_ais_val = df_events_ais_val.merge(df_cons_sum, on='sessionId', how='left')\n",
        "\n",
        "            # Preparar features para predi√ß√£o\n",
        "            features_missing = [f for f in features_available if f not in df_events_ais_val.columns]\n",
        "            for feat in features_missing:\n",
        "                df_events_ais_val[feat] = 0\n",
        "\n",
        "            df_pred_val = df_events_ais_val[features_available + ['shipName', 'startGMTDate']].copy()\n",
        "            df_pred_val[features_available] = df_pred_val[features_available].fillna(0)\n",
        "\n",
        "            X_val = df_pred_val[features_available].values\n",
        "\n",
        "            # Fazer predi√ß√µes com ensemble\n",
        "            predictions_val = {}\n",
        "            for name, model in models.items():\n",
        "                pred = model.predict(X_val)\n",
        "                predictions_val[name] = pred\n",
        "\n",
        "            # Ensemble com pesos\n",
        "            y_pred_val_ensemble = sum(predictions_val[name] * weight for name, weight in zip(models.keys(), weights))\n",
        "\n",
        "            df_pred_val['fouling_percentage'] = y_pred_val_ensemble\n",
        "\n",
        "            # Converter para IMO\n",
        "            def percentage_to_imo_rating(pct):\n",
        "                if pd.isna(pct):\n",
        "                    return np.nan\n",
        "                if pct < 0.5:\n",
        "                    return 0.0\n",
        "                elif pct < 1.0:\n",
        "                    return 0.5 + (pct - 0.5)\n",
        "                elif pct < 15.0:\n",
        "                    return 1.0 + (pct - 1.0) / 14.0\n",
        "                elif pct < 40.0:\n",
        "                    return 2.0 + (pct - 15.0) / 25.0\n",
        "                elif pct < 70.0:\n",
        "                    return 3.0 + (pct - 40.0) / 30.0\n",
        "                else:\n",
        "                    return 4.0\n",
        "\n",
        "            df_pred_val['fouling_rating_imo'] = df_pred_val['fouling_percentage'].apply(percentage_to_imo_rating)\n",
        "\n",
        "            # Preencher template\n",
        "            resultados_preenchidos = []\n",
        "\n",
        "            for idx, row in df_resultado.iterrows():\n",
        "                navio = str(row.get('Embarca√ß√£o', '')).strip()\n",
        "                data_alvo = row.get('Data')\n",
        "\n",
        "                if pd.isna(data_alvo) or navio == '' or navio == 'nan':\n",
        "                    continue\n",
        "\n",
        "                # Buscar predi√ß√µes para este navio\n",
        "                mask = df_pred_val['shipName'].str.upper() == navio.upper()\n",
        "                if not mask.any():\n",
        "                    mask = df_pred_val['shipName'].str.upper().str.contains(navio.upper(), na=False)\n",
        "\n",
        "                preds_navio = df_pred_val[mask].copy()\n",
        "\n",
        "                if preds_navio.empty:\n",
        "                    continue\n",
        "\n",
        "                # Encontrar predi√ß√£o mais pr√≥xima\n",
        "                preds_navio['time_diff'] = (preds_navio['startGMTDate'] - data_alvo).abs()\n",
        "                closest = preds_navio.loc[preds_navio['time_diff'].idxmin()]\n",
        "                pct = closest['fouling_percentage']\n",
        "                imo = closest['fouling_rating_imo']\n",
        "\n",
        "                # Classificar\n",
        "                if pct < 1.0:\n",
        "                    classe = \"Limpo/Micro\"\n",
        "                elif pct < 15.0:\n",
        "                    classe = \"Leve\"\n",
        "                elif pct < 40.0:\n",
        "                    classe = \"Moderada\"\n",
        "                elif pct < 70.0:\n",
        "                    classe = \"Pesada\"\n",
        "                else:\n",
        "                    classe = \"Cr√≠tica\"\n",
        "\n",
        "                condicao = f\"{pct:.1f}% ({classe}, IMO {imo:.2f})\"\n",
        "                data_formatada = data_alvo.strftime('%d/%m/%Y') if pd.notna(data_alvo) else ''\n",
        "\n",
        "                resultados_preenchidos.append({\n",
        "                    'Embarca√ß√£o': navio,\n",
        "                    'Data': data_formatada,\n",
        "                    'Condi√ß√£o do Casco': condicao\n",
        "                })\n",
        "\n",
        "            df_resultado_final = pd.DataFrame(resultados_preenchidos)\n",
        "\n",
        "            # Salvar resultado\n",
        "            output_file = 'RESULTADO_Validacao_Preenchido.xlsx'\n",
        "            df_resultado_final.to_excel(output_file, index=False)\n",
        "            print_success(f\"Resultado salvo em: {output_file}\")\n",
        "\n",
        "            # Salvar predi√ß√µes detalhadas\n",
        "            df_pred_export = df_pred_val[['shipName', 'startGMTDate', 'fouling_percentage',\n",
        "                                          'fouling_rating_imo']].copy()\n",
        "            df_pred_export.to_csv('predicoes_validacao_detalhadas.csv', index=False)\n",
        "            print_success(\"Predi√ß√µes detalhadas salvas em: predicoes_validacao_detalhadas.csv\")\n",
        "\n",
        "        else:\n",
        "            print_warning(\"Nenhum evento com dados AIS encontrado\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print_warning(f\"Erro durante valida√ß√£o com dados principais: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "print_header(\"SCRIPT CONCLU√çDO\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "uMfyXsgZG2Be",
        "outputId": "c51b8f6c-637e-41b3-e769-74b6675d8dd1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36mVALIDA√á√ÉO COM NAVIOS DE TESTE\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">VALIDA√á√ÉO COM NAVIOS DE TESTE</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Carregando dados de valida√ß√£o\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Carregando dados de valida√ß√£o<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m   Consumo de valida√ß√£o: \u001b[1;36m7613\u001b[0m registros\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span>   Consumo de valida√ß√£o: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7613</span> registros\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m   Dados navios de valida√ß√£o: \u001b[1;36m2\u001b[0m registros\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span>   Dados navios de valida√ß√£o: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> registros\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m   AIS TESTE \u001b[1;36m2\u001b[0m: \u001b[1;36m14761\u001b[0m registros\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span>   AIS TESTE <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14761</span> registros\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m   AIS TESTE \u001b[1;36m3\u001b[0m: \u001b[1;36m18336\u001b[0m registros\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span>   AIS TESTE <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18336</span> registros\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m \n",
              "Resumo dos dados de valida√ß√£o:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span> \n",
              "Resumo dos dados de valida√ß√£o:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Eventos: \u001b[1;36m4337\u001b[0m | AIS: \u001b[1;36m33097\u001b[0m | Template: \u001b[1;36m8\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Eventos: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4337</span> | AIS: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33097</span> | Template: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Processando eventos de valida√ß√£o\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Processando eventos de valida√ß√£o<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Agregando AIS: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4337/4337 [00:02<00:00, 1565.88it/s]\n",
            "Agregando AIS: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10889/10889 [00:07<00:00, 1498.28it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Calculando dias desde √∫ltima limpeza \u001b[1m(\u001b[0mIWS + DOCAGEM\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Calculando dias desde √∫ltima limpeza <span style=\"font-weight: bold\">(</span>IWS + DOCAGEM<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  28 eventos de limpeza IWS\n",
            "  163 eventos de DOCAGEM\n",
            "  Total: 191 eventos de limpeza combinados\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando dias desde limpeza: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2607/2607 [00:02<00:00, 900.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Origem da √∫ltima limpeza:\n",
            "    DOCAGEM: 2520 eventos\n",
            "    IWS: 60 eventos\n",
            "    none: 27 eventos\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m Resultado salvo em: RESULTADO_Validacao_Preenchido.xlsx\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span> Resultado salvo em: RESULTADO_Validacao_Preenchido.xlsx\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36mRELAT√ìRIO DE VALIDA√á√ÉO\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">RELAT√ìRIO DE VALIDA√á√ÉO</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                                Navios de Valida√ß√£o                                                \u001b[0m\n",
              "                                                                                                                   \n",
              " \u001b[1;36m \u001b[0m\u001b[1;36mNavio           \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mData      \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mIncrust.%\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mIMO\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mStatus \u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mDias*\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mPenalidade\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mCusto/Ano\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mCO2/Ano\u001b[0m\u001b[1;36m \u001b[0m \u001b[1;36m \u001b[0m\u001b[1;36mA√ß√£o    \u001b[0m\u001b[1;36m \u001b[0m \n",
              " ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mDANIEL PEREIRA  \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m27/05/2025\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 623*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mVICTOR OLIVEIRA \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m12/04/2025\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 689*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mHENRIQUE ALVES  \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m14/05/2025\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 928*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mNAVIO TESTE 2   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m01/08/2024\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m    100.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m1053*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mNAVIO TESTE 2   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m18/04/2025\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     99.9\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m1306*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     35.0%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$3.32M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m15.9kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mCARLA SILVA     \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m12/04/2025\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     89.5\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 414*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     31.5%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$2.99M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m14.3kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mNAVIO TESTE 3   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m01/06/2025\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     89.2\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 582*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     31.4%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$2.98M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m14.3kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              " \u001b[1;31m \u001b[0m\u001b[1;31mGABRIELA MARTINS\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m13/05/2025\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     72.8\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m4.0\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mCr√≠tica\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m 402*\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m     25.9%\u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m$2.46M   \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31m11.8kt \u001b[0m\u001b[1;31m \u001b[0m \u001b[1;31m \u001b[0m\u001b[1;31mImediata\u001b[0m\u001b[1;31m \u001b[0m \n",
              "                                                                                                                   \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                Navios de Valida√ß√£o                                                </span>\n",
              "                                                                                                                   \n",
              " <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Navio            </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Data       </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Incrust.% </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> IMO </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Status  </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Dias* </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Penalidade </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Custo/Ano </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> CO2/Ano </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> A√ß√£o     </span> \n",
              " ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> DANIEL PEREIRA   </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 27/05/2025 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  623* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> VICTOR OLIVEIRA  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 12/04/2025 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  689* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> HENRIQUE ALVES   </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 14/05/2025 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  928* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> NAVIO TESTE 2    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 01/08/2024 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">     100.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 1053* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> NAVIO TESTE 2    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 18/04/2025 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      99.9 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 1306* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      35.0% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $3.32M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 15.9kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> CARLA SILVA      </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 12/04/2025 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      89.5 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  414* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      31.5% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $2.99M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 14.3kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> NAVIO TESTE 3    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 01/06/2025 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      89.2 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  582* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      31.4% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $2.98M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 14.3kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> GABRIELA MARTINS </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 13/05/2025 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      72.8 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 4.0 </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Cr√≠tica </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  402* </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">      25.9% </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> $2.46M    </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 11.8kt  </span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Imediata </span> \n",
              "                                                                                                                   \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m Predi√ß√µes detalhadas salvas em: predicoes_validacao_detalhadas.csv\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span> Predi√ß√µes detalhadas salvas em: predicoes_validacao_detalhadas.csv\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m‚úì\u001b[0m \n",
              "Valida√ß√£o conclu√≠da! Arquivos gerados:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span> \n",
              "Valida√ß√£o conclu√≠da! Arquivos gerados:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    \u001b[1;36m1\u001b[0m. RESULTADO_Validacao_Preenchido.xlsx\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. RESULTADO_Validacao_Preenchido.xlsx\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    \u001b[1;36m2\u001b[0m. predicoes_validacao_detalhadas.csv\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. predicoes_validacao_detalhadas.csv\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36mSCRIPT CONCLU√çDO\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">SCRIPT CONCLU√çDO</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}